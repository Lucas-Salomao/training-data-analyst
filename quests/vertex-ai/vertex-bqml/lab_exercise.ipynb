{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "39d24a6a",
   "metadata": {},
   "source": [
    "# Implantar um modelo de propensão de rotatividade de usuários do BigQuery ML no Vertex AI para previsões on-line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c97e1100",
   "metadata": {},
   "source": [
    "## Objetivos de aprendizado"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a426ddad",
   "metadata": {},
   "source": [
    "* Explore e pré-processe uma amostra de dados do [Google Analytics 4](https://support.google.com/analytics/answer/7029846) no [BigQuery](https://cloud.google.com/bigquery) para aprendizado de máquina.\n",
    "* Treine um classificador do [BigQuery ML (BQML)](https://cloud.google.com/bigquery-ml) [XGBoost](https://xgboost.readthedocs.io/en/latest/) para prever a perda de usuários um aplicativo de jogos para celular.\n",
    "* Ajuste um classificador BQML XGBoost usando [recursos de ajuste de hiperparâmetro BQML](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree).\n",
    "* Avaliar o desempenho de um classificador BQML XGBoost.\n",
    "* Explique seu modelo XGBoost com atribuições de recursos globais de [BQML Explainable AI](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-xai-overview).\n",
    "* Gere previsões em lote com seu modelo BQML XGBoost.\n",
    "* Exporte um modelo BQML XGBoost para um [Google Cloud Storage](https://cloud.google.com/storage).\n",
    "* Carregue e implante um modelo BQML XGBoost em um endpoint [Vertex AI Prediction](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions) para previsões on-line."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32a258db",
   "metadata": {},
   "source": [
    "## Introdução"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d8d5372",
   "metadata": {},
   "source": [
    "Neste laboratório, você treinará, avaliará, explicará e gerará previsões on-line e em lote com um modelo XGBoost do BigQuery ML (BQML). Você usará um conjunto de dados do Google Analytics 4 de um aplicativo móvel real, Flood it! ([aplicativo Android](https://play.google.com/store/apps/details?id=com.labpixies.flood), [aplicativo iOS](https://itunes.apple.com/us/app/ flood-it!/id476943146?mt=8)), para determinar a probabilidade de os usuários retornarem ao aplicativo. Você gerará previsões em lote com seu modelo do BigQuery ML, além de exportá-lo e implantá-lo no **Vertex AI** para previsões on-line.\n",
    "\n",
    "O [BigQuery ML](https://cloud.google.com/bigquery-ml/docs/introduction) permite treinar e fazer inferência em lote com modelos de aprendizado de máquina no BigQuery usando consultas SQL padrão mais rapidamente, eliminando a necessidade de mover dados com menos linhas de código. [Vertex AI](https://cloud.google.com/vertex-ai) é a plataforma unificada complementar de próxima geração do Google Cloud para desenvolvimento de aprendizado de máquina. Ao desenvolver e implantar soluções de aprendizado de máquina BQML na Vertex AI, você pode aproveitar um serviço de previsão online escalável e ferramentas de MLOps para treinamento e monitoramento de modelos para melhorar significativamente sua produtividade de desenvolvimento, a capacidade de dimensionar seu fluxo de trabalho e a tomada de decisões com seus dados e acelerar tempo para valorizar.\n",
    "\n",
    "![BQML Vertex AI](./images/vertex-bqml-lab-architecture-diagram.png \"Vertex BQML Lab Architecture Diagram\")\n",
    "\n",
    "Observação: este laboratório é inspirado e estende a [previsão de rotatividade para desenvolvedores de jogos usando o Google Analytics 4 (GA4) e o BigQuery ML](https://cloud.google.com/blog/topics/developers-practitioners/churn-prediction-game -desenvolvedores-usando-google-analytics-4-ga4-and-bigquery-ml). Consulte a postagem do blog e o tutorial que o acompanha para obter mais detalhes sobre este caso de uso e o BigQuery ML. Neste laboratório, você dará um passo adiante e se concentrará em como a Vertex AI estende os recursos do BQML por meio da previsão on-line para que você possa incorporar as previsões de rotatividade de clientes nas UIs de tomada de decisão, como [painéis do Looker](https://looker.com/google -cloud), mas também previsões on-line diretamente nos aplicativos do cliente para impulsionar intervenções direcionadas, como incentivos direcionados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bce45947",
   "metadata": {},
   "source": [
    "### Caso de uso: modelagem de propensão à rotatividade de usuários no setor de jogos para dispositivos móveis"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14102f4b",
   "metadata": {},
   "source": [
    "De acordo com um [estudo de 2019](https://gameanalytics.com/reports/mobile-gaming-industry-analysis-h1-2019) sobre 100 mil jogos para celular da Mobile Gaming Industry Analysis, a maioria dos jogos para celular tem apenas 25% de retenção taxa para usuários após as primeiras 24 horas, sabe-se que qualquer jogo \"abaixo de 30% de retenção geralmente precisa de melhorias\". Para desenvolvedores de jogos para dispositivos móveis, melhorar a retenção de usuários é fundamental para a estabilidade da receita e o aumento da lucratividade. Na verdade, [pesquisa da Bain & Company](https://hbr.org/2014/10/the-value-of-keeping-the-right-customers) descobriu que um crescimento de 5% na taxa de retenção pode resultar em 25% a 95% nos lucros. Com custos mais baixos para reter os clientes existentes, o objetivo comercial dos desenvolvedores de jogos é claro: reduzir a rotatividade e melhorar a fidelidade do cliente para gerar lucratividade a longo prazo.\n",
    "\n",
    "Sua tarefa neste laboratório: usar o aprendizado de máquina para prever a propensão de desligamento do usuário após o primeiro dia, uma janela crucial de integração do usuário, e fornecer essas previsões on-line para informar intervenções como recompensas e notificações direcionadas no jogo."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4963f56a",
   "metadata": {},
   "source": [
    "## Configuração"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cbbab34",
   "metadata": {},
   "source": [
    "### Definição de Constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "edbc96b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupere e defina as variáveis de ambiente PROJECT_ID e REGION.\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "935a4807",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQ_LOCATION = 'US'\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b1bea9f",
   "metadata": {},
   "source": [
    "### Importe as bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4afdade5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import bigquery\n",
    "from google.cloud import aiplatform as vertexai\n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76acc5de",
   "metadata": {},
   "source": [
    "### Criar um bucket para o artifact storage"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abc13d5c",
   "metadata": {},
   "source": [
    "Crie um bucket globalmente exclusivo do Google Cloud Storage para armazenamento de artefatos. Você usará esse bucket para exportar seu modelo BQML posteriormente no laboratório e carregá-lo no Vertex AI."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7682097",
   "metadata": {},
   "outputs": [],
   "source": [
    "GCS_BUCKET = f\"{PROJECT_ID}-bqmlga4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c003d940",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil mb -l $REGION gs://$GCS_BUCKET"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd34ed14",
   "metadata": {},
   "source": [
    "### Criar um conjunto de dados do BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a93d1373",
   "metadata": {},
   "source": [
    "Em seguida, crie um conjunto de dados do BigQuery a partir deste notebook usando o [utilitário de linha de comando `bq` baseado em Python](https://cloud.google.com/bigquery/docs/bq-command-line-tool).\n",
    "\n",
    "Esse conjunto de dados agrupará suas visualizações de recursos, modelo e tabela de previsões. Você pode visualizá-lo no console do [BigQuery](https://pantheon.corp.google.com/bigquery)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd775fe7",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQ_DATASET = f\"{PROJECT_ID}:bqmlga4\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53014527",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq mk --location={BQ_LOCATION} --dataset {BQ_DATASET}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c8624c",
   "metadata": {},
   "source": [
    "### Inicialize o cliente Vertex Python SDK"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af877157",
   "metadata": {},
   "source": [
    "Importe o Vertex SDK for Python para seu ambiente Python e inicialize-o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d992f3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "vertexai.init(project=PROJECT_ID, location=REGION, staging_bucket=f\"gs://{GCS_BUCKET}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45dc2862",
   "metadata": {},
   "source": [
    "## Análise de dados exploratórios (EDA) no BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0cacbd08",
   "metadata": {},
   "source": [
    "Este laboratório usa um [conjunto de dados público do BigQuery]() que contém dados brutos de eventos de um aplicativo de jogos para dispositivos móveis real chamado **Flood it!** ([Aplicativo Android](https://play.google.com/store/apps/details?id=com.labpixies.flood), [iOS app](https://itunes.apple.com/us/app/flood-it!/id476943146?mt=8)).\n",
    "\n",
    "O esquema de dados é originário do Google Analytics para Firebase, mas é o mesmo esquema do [Google Analytics 4](https://support.google.com/analytics/answer/9358801).\n",
    "\n",
    "Dê uma olhada em uma amostra do conjunto de dados de eventos brutos usando a consulta abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "049d2d38",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT \n",
    "    *\n",
    "FROM\n",
    "  `firebase-public-project.analytics_153293282.events_*`\n",
    "    \n",
    "TABLESAMPLE SYSTEM (1 PERCENT)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ae1c8a",
   "metadata": {},
   "source": [
    "Nota: na célula acima, o Jupyterlab executa células começando com `%%bigquery` como consultas SQL."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "301298d2",
   "metadata": {},
   "source": [
    "O Google Analytics 4 usa um modelo de medição baseado em eventos e cada linha nesse conjunto de dados é um evento. Veja o [esquema completo](https://support.google.com/analytics/answer/7029846) e detalhes sobre cada coluna. Como você pode ver acima, certas colunas são registros aninhados e contêm informações detalhadas, como:\n",
    "\n",
    "* app_info\n",
    "* device\n",
    "* ecommerce\n",
    "* event_params\n",
    "* geo\n",
    "* traffic_source\n",
    "* user_properties\n",
    "* items*\n",
    "* web_info*"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47bbd90b",
   "metadata": {},
   "source": [
    "Este conjunto de dados contém 5,7 milhões de eventos de mais de 15 mil usuários."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80c0833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT \n",
    "    COUNT(DISTINCT user_pseudo_id) as count_distinct_users,\n",
    "    COUNT(event_timestamp) as count_events\n",
    "FROM\n",
    "  `firebase-public-project.analytics_153293282.events_*`"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "764fbeaa",
   "metadata": {},
   "source": [
    "## Preparação do conjunto de dados no BigQuery"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "751359e5",
   "metadata": {},
   "source": [
    "Agora que você tem uma noção melhor do conjunto de dados com o qual trabalhará, passará pela transformação de dados brutos de eventos em um conjunto de dados adequado para aprendizado de máquina usando comandos SQL no BigQuery. Especificamente, você irá:\n",
    "\n",
    "* Eventos agregados para que cada linha represente um ID de usuário exclusivo separado.\n",
    "* Defina o recurso **user churn label** para treinar seu modelo para previsão (por exemplo, 1 = cancelado, 0 = retornado).\n",
    "* Crie recursos **demográficos do usuário**.\n",
    "* Crie recursos **comportamentais do usuário** a partir de eventos de aplicativos agregados."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0880f4fa",
   "metadata": {},
   "source": [
    "### Definindo rotatividade para cada usuário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e71540a9",
   "metadata": {},
   "source": [
    "Há muitas maneiras de definir a perda de usuários, mas para os propósitos deste laboratório, você preverá a perda de um dia de usuários que não voltam e usam o aplicativo novamente após 24 horas do primeiro engajamento do usuário. Isso serve para capturar a rotatividade após a \"primeira impressão\" de um usuário do aplicativo ou da experiência de integração.\n",
    "\n",
    "Em outras palavras, após 24 horas do primeiro envolvimento de um usuário com o aplicativo:\n",
    "\n",
    "* se o usuário não mostrar nenhum dado de evento depois disso, o usuário será considerado **desconectado**.\n",
    "* se o usuário tiver pelo menos um ponto de dados de evento depois disso, o usuário será considerado **retornado**.\n",
    "\n",
    "Você também pode remover usuários que provavelmente nunca retornaram depois de passar apenas alguns minutos com o aplicativo, que às vezes é chamado de \"rejeição\". Por exemplo, você criará seu modelo apenas em usuários que passaram pelo menos 10 minutos com o aplicativo (usuários que não desistiram).\n",
    "\n",
    "A consulta abaixo define um usuário churned com a seguinte definição:\n",
    "\n",
    "**Rotatividade = \"qualquer usuário que passou pelo menos 10 minutos no aplicativo, mas depois de 24 horas desde o primeiro contato com o aplicativo, nunca mais usou o aplicativo\"**\n",
    "\n",
    "Você usará os dados brutos do evento, desde o primeiro toque (instalação do aplicativo) até o último toque, para identificar usuários cancelados e rejeitados na consulta de visualização `user_churn` abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab5c7d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.user_churn AS (\n",
    "  WITH firstlasttouch AS (\n",
    "    SELECT\n",
    "      user_pseudo_id,\n",
    "      MIN(event_timestamp) AS user_first_engagement,\n",
    "      MAX(event_timestamp) AS user_last_engagement\n",
    "    FROM\n",
    "      `firebase-public-project.analytics_153293282.events_*`\n",
    "    WHERE event_name=\"user_engagement\"\n",
    "    GROUP BY\n",
    "      user_pseudo_id\n",
    "\n",
    "  )\n",
    "  \n",
    "SELECT\n",
    "    user_pseudo_id,\n",
    "    user_first_engagement,\n",
    "    user_last_engagement,\n",
    "    EXTRACT(MONTH from TIMESTAMP_MICROS(user_first_engagement)) as month,\n",
    "    EXTRACT(DAYOFYEAR from TIMESTAMP_MICROS(user_first_engagement)) as julianday,\n",
    "    EXTRACT(DAYOFWEEK from TIMESTAMP_MICROS(user_first_engagement)) as dayofweek,\n",
    "\n",
    "    #adicione 24 horas ao primeiro toque do usuário\n",
    "    (user_first_engagement + 86400000000) AS ts_24hr_after_first_engagement,\n",
    "    \n",
    "    #rotatividade = 1 se last_touch dentro de 24 horas da instalação do aplicativo, senão 0\n",
    "    IF (user_last_engagement < (user_first_engagement + 86400000000),\n",
    "    1,\n",
    "    0 ) AS churned,\n",
    "    \n",
    "    #retornado = 1 se last_touch dentro de 10 min, senão 0\n",
    "    IF (user_last_engagement <= (user_first_engagement + 600000000),\n",
    "    1,\n",
    "    0 ) AS bounced,\n",
    "  FROM\n",
    "    firstlasttouch\n",
    "  GROUP BY\n",
    "    user_pseudo_id,\n",
    "    user_first_engagement,\n",
    "    user_last_engagement\n",
    "    );\n",
    "\n",
    "SELECT \n",
    "  * \n",
    "FROM \n",
    "  bqmlga4.user_churn \n",
    "LIMIT 100;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b731ce4c",
   "metadata": {},
   "source": [
    "Analise quantos dos 15 mil usuários rejeitaram e retornaram abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cdaa9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "    bounced,\n",
    "    churned, \n",
    "    COUNT(churned) as count_users\n",
    "FROM\n",
    "    bqmlga4.user_churn\n",
    "GROUP BY \n",
    "  bounced,\n",
    "  churned\n",
    "ORDER BY \n",
    "  bounced"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ab1fc447",
   "metadata": {},
   "source": [
    "Para os dados de treinamento, você acabará usando apenas dados onde rejeitados = 0. Com base nos 15 mil usuários, você pode ver que 5.557 (cerca de 41%) usuários rejeitaram nos primeiros dez minutos de seu primeiro envolvimento com o aplicativo. Dos 8.031 usuários restantes, 1.883 usuários (cerca de 23%) desistiram após 24 horas, o que você pode validar com a consulta abaixo:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9ae920e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "    COUNTIF(churned=1)/COUNT(churned) as churn_rate\n",
    "FROM\n",
    "    bqmlga4.user_churn\n",
    "WHERE bounced = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef78f94",
   "metadata": {},
   "source": [
    "### Extraia recursos demográficos do usuário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfea3b94",
   "metadata": {},
   "source": [
    "Há várias informações demográficas de usuários incluídas neste conjunto de dados, incluindo `app_info`, `device`, `ecommerce`, `event_params` e `geo`. Os recursos demográficos podem ajudar o modelo a prever se os usuários em determinados dispositivos ou países têm maior probabilidade de sair.\n",
    "\n",
    "Observe que os dados demográficos de um usuário podem mudar ocasionalmente (por exemplo, mudar de país). Para simplificar, você usará as informações demográficas que o Google Analytics 4 fornece quando o usuário interagiu pela primeira vez com o aplicativo, conforme indicado por MIN(event_timestamp) na consulta abaixo. Isso permite que cada usuário único seja representado por uma única linha."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd36306f",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.user_demographics AS (\n",
    "\n",
    "  WITH first_values AS (\n",
    "      SELECT\n",
    "          user_pseudo_id,\n",
    "          geo.country as country,\n",
    "          device.operating_system as operating_system,\n",
    "          device.language as language,\n",
    "          ROW_NUMBER() OVER (PARTITION BY user_pseudo_id ORDER BY event_timestamp DESC) AS row_num\n",
    "      FROM `firebase-public-project.analytics_153293282.events_*`\n",
    "      WHERE event_name=\"user_engagement\"\n",
    "      )\n",
    "  SELECT * EXCEPT (row_num)\n",
    "  FROM first_values\n",
    "  WHERE row_num = 1\n",
    "  );\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  bqmlga4.user_demographics\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11abe88b",
   "metadata": {},
   "source": [
    "### Agregar recursos comportamentais do usuário"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71dfe78b",
   "metadata": {},
   "source": [
    "Os dados comportamentais nos dados brutos do evento abrangem vários eventos - e, portanto, linhas - por usuário. O objetivo desta seção é agregar e extrair dados comportamentais para cada usuário, resultando em uma linha de dados comportamentais por usuário único.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b9be082c",
   "metadata": {},
   "source": [
    "Como primeiro passo, você pode explorar todos os eventos exclusivos que existem neste conjunto de dados, com base em event_name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "debac29c",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  event_name,\n",
    "  COUNT(event_name) as event_count\n",
    "FROM\n",
    "    `firebase-public-project.analytics_153293282.events_*`\n",
    "GROUP BY \n",
    "  event_name\n",
    "ORDER BY\n",
    "   event_count DESC"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6596f7be",
   "metadata": {},
   "source": [
    "Para este laboratório, para prever se um usuário sairá ou retornará, você pode começar contando o número de vezes que um usuário se envolve nos seguintes tipos de evento:\n",
    "\n",
    "* user_engagement\n",
    "* level_start_quickplay\n",
    "* level_end_quickplay\n",
    "* level_complete_quickplay\n",
    "* level_reset_quickplay\n",
    "* post_score\n",
    "* spend_virtual_currency\n",
    "* ad_reward\n",
    "* challenge_a_friend\n",
    "* completed_5_levels\n",
    "* use_extra_steps"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60502c0a",
   "metadata": {},
   "source": [
    "Na consulta SQL abaixo, você agregará os dados comportamentais calculando o número total de vezes em que cada um dos event_names acima ocorreu no conjunto de dados por usuário."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b016e18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.user_behavior AS (\n",
    "WITH\n",
    "  events_first24hr AS (\n",
    "    # Select user data only from first 24 hr of using the app.\n",
    "    SELECT\n",
    "      e.*\n",
    "    FROM\n",
    "      `firebase-public-project.analytics_153293282.events_*` e\n",
    "    JOIN\n",
    "      bqmlga4.user_churn c\n",
    "    ON\n",
    "      e.user_pseudo_id = c.user_pseudo_id\n",
    "    WHERE\n",
    "      e.event_timestamp <= c.ts_24hr_after_first_engagement\n",
    "    )\n",
    "SELECT\n",
    "  user_pseudo_id,\n",
    "  SUM(IF(event_name = 'user_engagement', 1, 0)) AS cnt_user_engagement,\n",
    "  SUM(IF(event_name = 'level_start_quickplay', 1, 0)) AS cnt_level_start_quickplay,\n",
    "  SUM(IF(event_name = 'level_end_quickplay', 1, 0)) AS cnt_level_end_quickplay,\n",
    "  SUM(IF(event_name = 'level_complete_quickplay', 1, 0)) AS cnt_level_complete_quickplay,\n",
    "  SUM(IF(event_name = 'level_reset_quickplay', 1, 0)) AS cnt_level_reset_quickplay,\n",
    "  SUM(IF(event_name = 'post_score', 1, 0)) AS cnt_post_score,\n",
    "  SUM(IF(event_name = 'spend_virtual_currency', 1, 0)) AS cnt_spend_virtual_currency,\n",
    "  SUM(IF(event_name = 'ad_reward', 1, 0)) AS cnt_ad_reward,\n",
    "  SUM(IF(event_name = 'challenge_a_friend', 1, 0)) AS cnt_challenge_a_friend,\n",
    "  SUM(IF(event_name = 'completed_5_levels', 1, 0)) AS cnt_completed_5_levels,\n",
    "  SUM(IF(event_name = 'use_extra_steps', 1, 0)) AS cnt_use_extra_steps,\n",
    "FROM\n",
    "  events_first24hr\n",
    "GROUP BY\n",
    "  user_pseudo_id\n",
    "  );\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  bqmlga4.user_behavior\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77089f30",
   "metadata": {},
   "source": [
    "### Prepare seus conjuntos de dados de treinamento/avaliação/teste para aprendizado de máquina"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8a868015",
   "metadata": {},
   "source": [
    "Nesta seção, agora você pode combinar essas três visualizações intermediárias (`user_churn`, `user_demographics` e `user_behavior`) na visualização final de dados de treinamento chamada `ml_features`. Aqui você também pode especificar rejeição = 0, para limitar os dados de treinamento apenas aos usuários que não \"rejeitam\" nos primeiros 10 minutos de uso do aplicativo.\n",
    "\n",
    "Observe na consulta abaixo que uma coluna `data_split` manual é criada na tabela do BigQuery ML usando [funções de hashing do BigQuery](https://towardsdatascience.com/ml-design-pattern-5-repeatable-sampling-c0ccb2889f39) para amostragem repetitiva. Especifica 80% de treinamento | 10% de avaliação | 20% de teste para avaliar o desempenho e a generalização do seu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448138e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE VIEW bqmlga4.ml_features AS (\n",
    "    \n",
    "  SELECT\n",
    "    dem.user_pseudo_id,\n",
    "    IFNULL(dem.country, \"Unknown\") AS country,\n",
    "    IFNULL(dem.operating_system, \"Unknown\") AS operating_system,\n",
    "    IFNULL(REPLACE(dem.language, \"-\", \"X\"), \"Unknown\") AS language,\n",
    "    IFNULL(beh.cnt_user_engagement, 0) AS cnt_user_engagement,\n",
    "    IFNULL(beh.cnt_level_start_quickplay, 0) AS cnt_level_start_quickplay,\n",
    "    IFNULL(beh.cnt_level_end_quickplay, 0) AS cnt_level_end_quickplay,\n",
    "    IFNULL(beh.cnt_level_complete_quickplay, 0) AS cnt_level_complete_quickplay,\n",
    "    IFNULL(beh.cnt_level_reset_quickplay, 0) AS cnt_level_reset_quickplay,\n",
    "    IFNULL(beh.cnt_post_score, 0) AS cnt_post_score,\n",
    "    IFNULL(beh.cnt_spend_virtual_currency, 0) AS cnt_spend_virtual_currency,\n",
    "    IFNULL(beh.cnt_ad_reward, 0) AS cnt_ad_reward,\n",
    "    IFNULL(beh.cnt_challenge_a_friend, 0) AS cnt_challenge_a_friend,\n",
    "    IFNULL(beh.cnt_completed_5_levels, 0) AS cnt_completed_5_levels,\n",
    "    IFNULL(beh.cnt_use_extra_steps, 0) AS cnt_use_extra_steps,\n",
    "    chu.user_first_engagement,\n",
    "    chu.month,\n",
    "    chu.julianday,\n",
    "    chu.dayofweek,\n",
    "    chu.churned,\n",
    "    # https://towardsdatascience.com/ml-design-pattern-5-repeatable-sampling-c0ccb2889f39\n",
    "    # BQML Hyperparameter tuning requires STRING 3 partition data_split column.\n",
    "    # 80% 'TRAIN' | 10%'EVAL' | 10% 'TEST'    \n",
    "    CASE\n",
    "      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) <= 7\n",
    "        THEN 'TRAIN'\n",
    "      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) = 8\n",
    "        THEN 'EVAL'\n",
    "      WHEN ABS(MOD(FARM_FINGERPRINT(dem.user_pseudo_id), 10)) = 9\n",
    "        THEN 'TEST'    \n",
    "          ELSE '' END AS data_split\n",
    "  FROM\n",
    "    bqmlga4.user_churn chu\n",
    "  LEFT OUTER JOIN\n",
    "    bqmlga4.user_demographics dem\n",
    "  ON \n",
    "    chu.user_pseudo_id = dem.user_pseudo_id\n",
    "  LEFT OUTER JOIN \n",
    "    bqmlga4.user_behavior beh\n",
    "  ON\n",
    "    chu.user_pseudo_id = beh.user_pseudo_id\n",
    "  WHERE chu.bounced = 0\n",
    "  );\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  bqmlga4.ml_features\n",
    "LIMIT 10"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccc4f5f9",
   "metadata": {},
   "source": [
    "### Validar divisões de recursos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0af097e0",
   "metadata": {},
   "source": [
    "Run the query below to validate the number of examples in each data partition for the 80% train |10% eval |10% test split.\n",
    "\n",
    "Execute a consulta abaixo para validar o número de exemplos em cada partição de dados para  80% treinamento |10% avaliação |10% teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb419c16",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  data_split,\n",
    "  COUNT(*) AS n_examples\n",
    "FROM bqmlga4.ml_features\n",
    "GROUP BY data_split"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2767dae",
   "metadata": {},
   "source": [
    "## Treine e ajuste um modelo de propensão BQML XGBoost para prever a perda de clientes"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3a861a0",
   "metadata": {},
   "source": [
    "O código a seguir treina e ajusta os hiperparâmetros para um modelo XGBoost. PARA fornecer uma demonstração mínima de ajuste de hiperparâmetros BQML neste laboratório, este modelo levará cerca de 18 minutos para treinar e ajustar com seu espaço de pesquisa restrito e baixo número de tentativas. Na prática, você geralmente precisa de [pelo menos 10 testes por hiperparâmetro](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-hyperparameter-tuning#how_many_trials_do_i_need_to_tune_a_model) para obter melhores resultados .\n",
    "\n",
    "Para obter mais informações sobre os hiperparâmetros padrão usados, você pode ler a documentação:\n",
    "[Instrução CREATE MODEL para modelos de árvore otimizada usando XGBoost](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da974b2b",
   "metadata": {},
   "source": [
    "|Model   | BQML model_type | Vantagens | Desvantagens| \n",
    "|:-------|:----------:|:----------:|-------------:|\n",
    "|XGBoost |     BOOSTED_TREE_CLASSIFIER [(documentation)](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-create-boosted-tree)       |   Alto desempenho do modelo com importâncias de recursos e explicabilidade | Mais lento para treinar do que BQML LOGISTIC_REG |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "577c9658",
   "metadata": {},
   "source": [
    "Observação: quando você executa a instrução CREATE MODEL, o BigQuery ML pode dividir automaticamente seus dados em treinamento e teste para que você possa avaliar imediatamente o desempenho do seu modelo após o treinamento. Esta é uma ótima opção para prototipagem rápida de modelos. Neste laboratório, no entanto, você dividirá seus dados manualmente acima usando hash para divisões de dados reproduzíveis que podem ser usadas comparando avaliações de modelo em diferentes execuções."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f84f45",
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_NAME=\"churn_xgb\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d4bbf26",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE MODEL bqmlga4.churn_xgb\n",
    "\n",
    "OPTIONS(\n",
    "  MODEL_TYPE=\"BOOSTED_TREE_CLASSIFIER\",\n",
    "  # Declare label column.\n",
    "  INPUT_LABEL_COLS=[\"churned\"],\n",
    "  # Specify custom data splitting using the `data_split` column.\n",
    "  DATA_SPLIT_METHOD=\"CUSTOM\",\n",
    "  DATA_SPLIT_COL=\"data_split\",\n",
    "  # Enable Vertex Explainable AI aggregated feature attributions.\n",
    "  ENABLE_GLOBAL_EXPLAIN=True,\n",
    "  # Hyperparameter tuning arguments.\n",
    "  num_trials=8,\n",
    "  max_parallel_trials=4,\n",
    "  HPARAM_TUNING_OBJECTIVES=[\"roc_auc\"],\n",
    "  EARLY_STOP=True,\n",
    "  # Hyperpameter search space.\n",
    "  LEARN_RATE=HPARAM_RANGE(0.01, 0.1),\n",
    "  MAX_TREE_DEPTH=HPARAM_CANDIDATES([5,6])\n",
    ") AS\n",
    "\n",
    "SELECT\n",
    "  * EXCEPT(user_pseudo_id)\n",
    "FROM\n",
    "  bqmlga4.ml_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2beffd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT *\n",
    "FROM\n",
    "  ML.TRIAL_INFO(MODEL `bqmlga4.churn_xgb`);"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fbb9dc3a",
   "metadata": {},
   "source": [
    "## Avalie o desempenho do modelo BQML XGBoost"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19c50568",
   "metadata": {},
   "source": [
    "Quando o treinamento terminar, execute [ML.EVALUATE](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-evaluate) para retornar as métricas de avaliação do modelo. Por padrão, todas as avaliações do modelo serão retornadas, portanto, a consulta abaixo apenas retorna o desempenho do modelo para uma primeira avaliação ideal."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bb9896b",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.EVALUATE(MODEL bqmlga4.churn_xgb)\n",
    "WHERE trial_id=1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e0537c9",
   "metadata": {},
   "source": [
    "ML.EVALUATE gera o [precision, recall](https://developers.google.com/machine-learning/crash-course/classification/precision-and-recall), [accuracy](https://developers.google.com/machine-learning/crash-course/classification/accuracy), [log_loss](https://en.wikipedia.org/wiki/Loss_functions_for_classification#Logistic_loss), [f1_score](https://en.wikipedia.org/wiki/F-score) e [roc_auc](https://developers.google.com/machine-learning/crash-course/classification/roc-and-auc) usando o limite de classificação padrão de 0,5, que pode ser modificado por usando o parâmetro opcional `THRESHOLD`."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22da8688",
   "metadata": {},
   "source": [
    "Em seguida, use a função [ML.CONFUSION_MATRIX](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-confusion) para retornar uma matriz de confusão para o modelo de classificação de entrada e dados de entrada.\n",
    "\n",
    "Para obter mais informações sobre matrizes de confusão, leia uma explicação detalhada [aqui](https://developers.google.com/machine-learning/crash-course/classification/true-false-positive-negative)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f15b2e45",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  expected_label,\n",
    "  _0 AS predicted_0,\n",
    "  _1 AS predicted_1\n",
    "FROM\n",
    "  ML.CONFUSION_MATRIX(MODEL bqmlga4.churn_xgb)\n",
    "WHERE trial_id=1;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64cdbf52",
   "metadata": {},
   "source": [
    "Você também pode plotar a curva AUC-ROC usando [ML.ROC_CURVE](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-roc) para retornar as métricas para diferentes valores limite para o modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1f9e493",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery df_roc --project $PROJECT_ID\n",
    "\n",
    "SELECT * FROM ML.ROC_CURVE(MODEL bqmlga4.churn_xgb) WHERE trial_id=1;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da715945",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_roc.plot(x=\"false_positive_rate\", y=\"recall\", title=\"AUC-ROC curve\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e51a9bc",
   "metadata": {},
   "source": [
    "## Inspecione as atribuições de recursos globais"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1e4a89b",
   "metadata": {},
   "source": [
    "Para fornecer mais contexto ao desempenho do seu modelo, você pode usar o [ML.GLOBAL_EXPLAIN](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-global-explain#get_global_feature_importance_for_each_class_of_a_boosted_tree_classifier_model ) que aproveita o Vertex Explainable AI como back-end. [Vertex Explainable AI](https://cloud.google.com/vertex-ai/docs/explainable-ai) ajuda você a entender as saídas do seu modelo para tarefas de classificação e regressão. Especificamente, o Vertex AI informa o quanto cada recurso nos dados contribuiu para o resultado previsto do seu modelo. Você pode usar essas informações para verificar se o modelo está se comportando conforme o esperado, identificar e mitigar vieses em seus modelos e obter ideias de maneiras de melhorar seu modelo e seus dados de treinamento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b505dae3",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.GLOBAL_EXPLAIN(MODEL bqmlga4.churn_xgb)\n",
    "ORDER BY\n",
    "  attribution DESC;"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b471e6ee",
   "metadata": {},
   "source": [
    "## Gerar previsões em lote"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ea8623c1",
   "metadata": {},
   "source": [
    "Você pode gerar previsões em lote para seu modelo BQML XGBoost usando [ML.PREDICT](https://cloud.google.com/bigquery-ml/docs/reference/standard-sql/bigqueryml-syntax-predict)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b117c407",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "SELECT\n",
    "  *\n",
    "FROM\n",
    "  ML.PREDICT(MODEL bqmlga4.churn_xgb,\n",
    "  (SELECT * FROM bqmlga4.ml_features WHERE data_split = \"TEST\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32dac74c",
   "metadata": {},
   "source": [
    "A consulta a seguir retorna a probabilidade de o usuário retornar após 24 horas. Quanto maior a probabilidade e mais próximo de 1, maior a probabilidade de o usuário se desligar, e quanto mais próximo de 0, maior a probabilidade de o usuário retornar."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7411bff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery --project $PROJECT_ID\n",
    "\n",
    "CREATE OR REPLACE TABLE bqmlga4.churn_predictions AS (\n",
    "SELECT\n",
    "  user_pseudo_id,\n",
    "  churned,\n",
    "  predicted_churned,\n",
    "  predicted_churned_probs[OFFSET(0)].prob as probability_churned\n",
    "FROM\n",
    "  ML.PREDICT(MODEL bqmlga4.churn_xgb,\n",
    "  (SELECT * FROM bqmlga4.ml_features))\n",
    ");"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c037410",
   "metadata": {},
   "source": [
    "## Exporte um modelo BQML para o Vertex AI para previsões online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a36d9005",
   "metadata": {},
   "source": [
    "Consulte o Guia oficial do BigQuery ML: [Exportar um modelo do BigQuery ML para previsão on-line](https://cloud.google.com/bigquery-ml/docs/export-model-tutorial) para mais detalhes."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6593da8c",
   "metadata": {},
   "source": [
    "### Exportar modelo BQML para GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4dfedfdd",
   "metadata": {},
   "source": [
    "Você usará o comando `bq extract` na ferramenta de linha de comando `bq` para exportar seus recursos do modelo BQML XGBoost para o Google Cloud Storage para persistência. Consulte a [documentação](https://cloud.google.com/bigquery-ml/docs/exporting-models) para opções adicionais de exportação de modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94f50a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "BQ_MODEL = f\"{BQ_DATASET}.{MODEL_NAME}\"\n",
    "BQ_MODEL_EXPORT_DIR = f\"gs://{GCS_BUCKET}/{MODEL_NAME}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee61430a",
   "metadata": {},
   "outputs": [],
   "source": [
    "!bq --location=$BQ_LOCATION extract \\\n",
    "--destination_format ML_XGBOOST_BOOSTER \\\n",
    "--model $BQ_MODEL \\\n",
    "$BQ_MODEL_EXPORT_DIR"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f336458",
   "metadata": {},
   "source": [
    "Navegue até [Google Cloud Storage](https://pantheon.corp.google.com/storage) no Google Cloud Console para `\"gs://{GCS_BUCKET}/{MODEL_NAME}\"`. Valide se você vê seus ativos de modelo exportados no formato abaixo:\n",
    "\n",
    "```\n",
    "|--/{GCS_BUCKET}/{MODEL_NAME}/\n",
    "   |--/assets/                       # Contains preprocessing code.  \n",
    "      |--0_categorical_label.txt     # Contains country vocabulary.\n",
    "      |--1_categorical_label.txt     # Contains operating_system vocabulary.\n",
    "      |--2_categorical_label.txt     # Contains language vocabulary.\n",
    "      |--model_metadata.json         # contains model feature and label mappings.\n",
    "   |--main.py                        # Can be called for local training runs.\n",
    "   |--model.bst                      # XGBoost saved model format.\n",
    "   |--xgboost_predictor-0.1.tar.gz   # Compress XGBoost model with prediction function. \n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71122b86",
   "metadata": {},
   "source": [
    "### Carregue o modelo BQML para o Vertex AI do GCS"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc20e5e7",
   "metadata": {},
   "source": [
    "O Vertex AI contém contêineres otimizados de treinamento e previsão pré-criados para estruturas populares de ML, como TensorFlow, Pytorch e XGBoost. Você fará o upload do seu XGBoost do GCS para o Vertex AI e fornecerá o [mais recente contêiner de previsão Vertex XGBoost pré-criado](https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers) para executar seu código de modelo para gerar previsões nas células abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c86cd67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_URI='us-docker.pkg.dev/vertex-ai/prediction/xgboost-cpu.1-4:latest'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3278567",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = vertexai.Model.upload(\n",
    "    display_name=MODEL_NAME,\n",
    "    artifact_uri=BQ_MODEL_EXPORT_DIR,\n",
    "    serving_container_image_uri=IMAGE_URI,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0874197c",
   "metadata": {},
   "source": [
    "### Implante um Vertex `Endpoint` para previsões online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1410ebc6",
   "metadata": {},
   "source": [
    "Antes de usar seu modelo para fazer previsões, você precisa implantá-lo em um objeto `Endpoint`. Ao implantar um modelo em um `endpoint`, você associa recursos físicos (de máquina) a esse modelo para permitir que ele atenda a previsões online. As previsões online têm requisitos de baixa latência; fornecer recursos para o modelo com antecedência reduz a latência. Você pode fazer isso chamando a função deploy no recurso `Model`. Isso fará duas coisas:\n",
    "\n",
    "1. Crie um recurso `Endpoint` para implantar o recurso `Model`.\n",
    "2. Implante o recurso `Model` no recurso `Endpoint`.\n",
    "\n",
    "A função `deploy()` recebe os seguintes parâmetros:\n",
    "\n",
    "* `deployed_model_display_name`: Um nome legível para o modelo implementado.\n",
    "* `traffic_split`: Porcentagem de tráfego no endpoint que vai para este modelo, que é especificado como um dicionário de um ou mais pares de chave/valor. Se for apenas um modelo, especifique como { \"0\": 100 }, em que \"0\" se refere a esse modelo sendo carregado e 100 significa 100% do tráfego.\n",
    "* `machine_type`: O tipo de máquina a ser usada para treinamento.\n",
    "* `accelerator_type`: O tipo de acelerador de hardware.\n",
    "* `accelerator_count`: O número de aceleradores a serem anexados a uma réplica do trabalhador.\n",
    "* `starting_replica_count`: o número de instâncias de computação a serem provisionadas inicialmente.\n",
    "* `max_replica_count`: o número máximo de instâncias de computação para escalar. Neste laboratório, apenas uma instância é provisionada.\n",
    "* `explanation_parameters`: Metadados para configurar o método de aprendizado Explainable AI.\n",
    "* `explanation_metadata`: Metadados que descrevem seu modelo TensorFlow para IA explicativa, como recursos, tensores de entrada e saída.\n",
    "\n",
    "Observação: isso pode levar cerca de 3 a 5 minutos para provisionar recursos de previsão para seu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df5368fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = model.deploy(\n",
    "    traffic_split={\"0\": 100},\n",
    "    machine_type=\"n1-standard-2\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8448a1",
   "metadata": {},
   "source": [
    "### Modelo de consulta para previsões on-line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b67ca13",
   "metadata": {},
   "source": [
    "O XGBoost aceita apenas entradas de recursos numéricos. Quando você treinou seu modelo BQML acima com a instrução CREATE MODEL, ele tratou automaticamente a codificação de recursos categóricos como `país` do usuário, `sistema operacional` e `idioma` em representações numéricas. Para que nosso modelo exportado gere previsões on-line, você usará os arquivos de vocabulário de recursos categóricos exportados na pasta `assets/` do diretório de seu modelo e o código de pré-processamento Scikit-Learn abaixo para mapear suas instâncias de teste para valores numéricos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b647538",
   "metadata": {},
   "outputs": [],
   "source": [
    "CATEGORICAL_FEATURES = ['country',\n",
    "                        'operating_system',\n",
    "                        'language']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18bb0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OrdinalEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "350c5727",
   "metadata": {},
   "outputs": [],
   "source": [
    "def _build_cat_feature_encoders(cat_feature_list, gcs_bucket, model_name, na_value='Unknown'):\n",
    "    \"\"\"Build categorical feature encoders for mapping text to integers for XGBoost inference. \n",
    "    Args:\n",
    "      cat_feature_list (list): List of string feature names.\n",
    "      gcs_bucket (str): A string path to your Google Cloud Storage bucket.\n",
    "      model_name (str): A string model directory in GCS where your BQML model was exported to.\n",
    "      na_value (str): default is 'Unknown'. String value to replace any vocab NaN values prior to encoding.\n",
    "    Returns:\n",
    "      feature_encoders (dict): A dictionary containing OrdinalEncoder objects for integerizing \n",
    "        categorical features that has the format [feature] = feature encoder.\n",
    "    \"\"\"\n",
    "    \"\"\"Construa codificadores de recursos categóricos para mapear texto para inteiros para inferência do XGBoost.\n",
    "     Args:\n",
    "       cat_feature_list (list): Lista de nomes de recursos de string.\n",
    "       gcs_bucket (str): um caminho de string para seu bucket do Google Cloud Storage.\n",
    "       model_name (str): Um diretório de modelo de string no GCS para o qual seu modelo BQML foi exportado.\n",
    "       na_value (str): o padrão é 'Desconhecido'. Valor de string para substituir quaisquer valores de vocab NaN antes da codificação.\n",
    "     Devoluções:\n",
    "       feature_encoders (dict): Um dicionário contendo objetos OrdinalEncoder para inteiros\n",
    "         feições categóricas que tem o formato [feature] = codificador de feições.\n",
    "     \"\"\"\n",
    "    \n",
    "    feature_encoders = {}\n",
    "    \n",
    "    for idx, feature in enumerate(cat_feature_list):\n",
    "        feature_encoder = OrdinalEncoder(handle_unknown=\"use_encoded_value\", unknown_value=-1)\n",
    "        feature_vocab_file = f\"gs://{gcs_bucket}/{model_name}/assets/{idx}_categorical_label.txt\"\n",
    "        feature_vocab_df = pd.read_csv(feature_vocab_file, delimiter = \"\\t\", header=None).fillna(na_value)\n",
    "        feature_encoder.fit(feature_vocab_df.values)\n",
    "        feature_encoders[feature] = feature_encoder\n",
    "    \n",
    "    return feature_encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809875a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_xgboost(instances, cat_feature_list, feature_encoders):\n",
    "    \"\"\"Transform instances to numerical values for inference.\n",
    "    Args:\n",
    "      instances (list[dict]): A list of feature dictionaries with the format feature: value. \n",
    "      cat_feature_list (list): A list of string feature names.\n",
    "      feature_encoders (dict): A dictionary with the format feature: feature_encoder.\n",
    "    Returns:\n",
    "      transformed_instances (list[list]): A list of lists containing numerical feature values needed\n",
    "        for Vertex XGBoost inference.\n",
    "    \"\"\"\n",
    "\n",
    "    \"\"\"Transforme instâncias em valores numéricos para inferência.\n",
    "     Args:\n",
    "       instâncias (list[dict]): Uma lista de dicionários de recursos com o formato feature: value.\n",
    "       cat_feature_list (list): Uma lista de nomes de recursos de string.\n",
    "       feature_encoders (dict): Um dicionário com o formato feature: feature_encoder.\n",
    "     Devoluções:\n",
    "       transformado_instances (list[list]): Uma lista de listas contendo valores numéricos de recursos necessários\n",
    "         para inferência Vertex XGBoost.\n",
    "     \"\"\"\n",
    "     \n",
    "    transformed_instances = []\n",
    "    \n",
    "    for instance in instances:\n",
    "        for feature in cat_feature_list:\n",
    "            feature_int = feature_encoders[feature].transform([[instance[feature]]]).item()\n",
    "            instance[feature] = feature_int\n",
    "            instance_list = list(instance.values())\n",
    "        transformed_instances.append(instance_list)\n",
    "\n",
    "    return transformed_instances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eae41101",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um dicionário de codificadores de recursos categóricos ordinais.\n",
    "feature_encoders = _build_cat_feature_encoders(CATEGORICAL_FEATURES, GCS_BUCKET, MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "201f0aa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery test_df --project $PROJECT_ID \n",
    "\n",
    "SELECT* EXCEPT (user_pseudo_id, churned, data_split)\n",
    "FROM bqmlga4.ml_features\n",
    "WHERE data_split=\"TEST\"\n",
    "LIMIT 3;"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d397bc03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converta registros de dataframe em dicionários de recursos para pré-processamento por nome de recurso.\n",
    "test_instances = test_df.astype(str).to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e19ade61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aplique o pré-processamento para transformar recursos categóricos e retornar instâncias numéricas para previsão.\n",
    "transformed_test_instances = preprocess_xgboost(test_instances, CATEGORICAL_FEATURES, feature_encoders)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "873c0db2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Gere previsões do modelo implantado no Vertex AI Endpoint.\n",
    "predictions = endpoint.predict(instances=transformed_test_instances)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3a08430",
   "metadata": {},
   "outputs": [],
   "source": [
    "for idx, prediction in enumerate(predictions.predictions):\n",
    "    # Rótulos de classe [1,0] recuperados de model_metadata.json no diretório do modelo GCS.\n",
    "    # O padrão de classificação binária BQML é 0,5 com \"Churn\" acima e abaixo de \"Not Churn\".\n",
    "    is_churned = \"Churn\" if prediction[0] >= 0.5 else \"Not Churn\"\n",
    "    print(f\"Prediction: Customer {idx} - {is_churned} {prediction}\")\n",
    "    print(test_df.iloc[idx].astype(str).to_json() + \"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7a4e13f",
   "metadata": {},
   "source": [
    "## Próximos passos"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f0d1f2c",
   "metadata": {},
   "source": [
    "Parabéns! Neste laboratório, você treinou, ajustou, explicou e implantou um modelo de desligamento de usuários do BigQuery ML para gerar previsões de desligamento on-line e em lote de alto impacto comercial para clientes-alvo com probabilidade de desligamento com intervenções como recompensas no jogo e notificações de lembrete.\n",
    "\n",
    "Neste laboratório, você usou `user_psuedo_id` como um identificador de usuário. Como próximas etapas, você pode estender esse código ainda mais fazendo com que seu aplicativo retorne um `user_id` para o Google Analytics para que você possa juntar as previsões do seu modelo com dados primários adicionais, como histórico de compras e dados de engajamento de marketing. Isso permite integrar previsões em lote aos painéis do Looker para ajudar as equipes de produto a priorizar melhorias na experiência do usuário e as equipes de marketing criar intervenções direcionadas ao usuário, como e-mails de lembrete para melhorar a retenção.\n",
    "\n",
    "Ao ter seu modelo no Vertex AI Prediction, você também tem um serviço de previsão escalável para chamar de seu aplicativo para integrar diretamente as previsões on-line, a fim de personalizar as experiências de jogo do usuário e permitir notificações direcionadas de criação de hábitos.\n",
    "\n",
    "À medida que você coleta mais dados de seus usuários, convém avaliar regularmente seu modelo com dados novos e treinar novamente o modelo se perceber que a qualidade do modelo está diminuindo. O [Vertex Pipelines](https://cloud.google.com/vertex-ai/docs/pipelines/introduction) pode ajudar você a automatizar, monitorar e controlar suas soluções de ML orquestrando seu fluxo de trabalho BQML sem servidor e armazenando os artefatos do seu fluxo de trabalho usando [Vertex ML Metadata](https://cloud.google.com/vertex-ai/docs/ml-metadata/introduction). Para outra alternativa para modelos BQML contínuos, confira a postagem do blog [Continuous model assessment with BigQuery ML, Stored Procedures, and Cloud Scheduler](https://cloud.google.com/blog/topics/developers-practitioners/continuous-model-assessment-bigquery-ml-stored-procedures-and-cloud-scheduler).\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a04b58a0",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1593ed77",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m80",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m80"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
