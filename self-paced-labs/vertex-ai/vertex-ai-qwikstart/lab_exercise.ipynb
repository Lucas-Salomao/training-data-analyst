{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "81e68768",
   "metadata": {},
   "source": [
    "# Vertex AI: Qwik Start"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8f3be9d1",
   "metadata": {},
   "source": [
    "## Objetivos de aprendizado\n",
    "\n",
    "* Treine um modelo do TensorFlow localmente em um [**Vertex Notebook**](https://cloud.google.com/vertex-ai/docs/general/notebooks?hl=sv) hospedado.\n",
    "* Crie um artefato [**conjunto de dados tabular gerenciado**](https://cloud.google.com/vertex-ai/docs/training/using-managed-datasets?hl=sv) para rastreamento de experimentos.\n",
    "* Conteinerize seu código de treinamento com [**Cloud Build**](https://cloud.google.com/build) e envie-o para [**Google Cloud Artifact Registry**](https://cloud.google.com/artifact-registry).\n",
    "* Execute um [**trabalho de treinamento personalizado da Vertex AI**](https://cloud.google.com/vertex-ai/docs/training/custom-training) com seu contêiner de modelo personalizado.\n",
    "* Use [**Vertex TensorBoard**](https://cloud.google.com/vertex-ai/docs/experiments/tensorboard-overview) para visualizar o desempenho do modelo.\n",
    "* Implante seu modelo treinado em um [**Vertex Online Prediction Endpoint**](https://cloud.google.com/vertex-ai/docs/predictions/getting-predictions) para fornecer previsões.\n",
    "* Solicite uma previsão e explicação online e veja a resposta."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7a746be",
   "metadata": {},
   "source": [
    "## Introdução: previsão do valor da vida útil do cliente (CLV) com BigQuery e TensorFlow na Vertex AI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "76bf82e0",
   "metadata": {},
   "source": [
    "Neste laboratório, você usará o [BigQuery](https://cloud.google.com/bigquery) para processamento e análise exploratória de dados e o [Vertex AI](https://cloud.google.com/vertex-ai ) para treinar e implantar um modelo TensorFlow Regressor personalizado para prever o valor da vida útil do cliente (CLV). O objetivo do laboratório é apresentar a Vertex AI por meio de um caso de uso real de alto valor - CLV preditivo. Você começará com um fluxo de trabalho local do BigQuery e TensorFlow com o qual já deve estar familiarizado e progredirá para treinar e implantar seu modelo na nuvem com a Vertex AI.\n",
    "\n",
    "![Vertex AI](./images/vertex-ai-overview.png \"Vertex AI Overview\")\n",
    "\n",
    "A Vertex AI é a plataforma unificada de próxima geração do Google Cloud para desenvolvimento de machine learning e a sucessora da AI Platform anunciada no Google I/O em maio de 2021. Ao desenvolver soluções de machine learning na Vertex AI, você pode aproveitar os mais recentes componentes pré-criados de ML e AutoML para aumentar significativamente a produtividade do desenvolvimento, a capacidade de dimensionar seu fluxo de trabalho e a tomada de decisões com seus dados e acelerar o tempo de retorno."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4fe3b8c6",
   "metadata": {},
   "source": [
    "### CLV preditivo: quanto valor monetário os clientes existentes trarão para a empresa no futuro\n",
    "\n",
    "O CLV preditivo é um caso de uso comercial de ML de alto impacto. CLV é o valor passado de um cliente mais seu valor futuro previsto. O objetivo do CLV preditivo é prever quanto valor monetário um usuário trará para o negócio em um intervalo de tempo futuro definido com base em transações históricas.\n",
    "\n",
    "Ao conhecer o CLV, você pode desenvolver estratégias de ROI positivas e tomar decisões sobre quanto dinheiro investir na aquisição de novos clientes e na retenção dos existentes para aumentar a receita e o lucro.\n",
    "\n",
    "Depois que seu modelo de ML for um sucesso, você poderá usar os resultados para identificar os clientes com maior probabilidade de gastar dinheiro do que os outros e fazê-los responder às suas ofertas e descontos com maior frequência. Esses clientes, com maior valor vitalício, são seu principal alvo de marketing para aumentar a receita.\n",
    "\n",
    "Ao usar a abordagem de aprendizado de máquina para prever o valor de seus clientes que você usará neste laboratório, você pode priorizar suas próximas ações, como as seguintes:\n",
    "\n",
    "* Decida quais clientes segmentar com publicidade para aumentar a receita.\n",
    "* Identifique quais segmentos de clientes são mais lucrativos e planeje como mover os clientes de um segmento para outro.\n",
    "\n",
    "Sua tarefa é prever o valor futuro dos clientes existentes com base em seu histórico de transações conhecido.\n",
    "\n",
    "![CLV](./images/clv-rfm.svg \"Valor vitalício do cliente\")\n",
    "Fonte: [Centro de Arquitetura em Nuvem - Prevendo o valor da vida útil do cliente com AI Platform: treinando os modelos](https://cloud.google.com/architecture/clv-prediction-with-offline-training-train)\n",
    "\n",
    "Há uma forte correlação positiva entre a recência, a frequência e a quantia gasta em cada compra que cada cliente faz e seu CLV. Consequentemente, você aproveitará esses recursos em seu modelo de ML. Para este laboratório, eles são definidos como:\n",
    "\n",
    "* **Recência**: o tempo entre a última compra e hoje, representado pela distância entre o círculo mais à direita e a linha pontilhada vertical marcada como \"Agora\".\n",
    "* **Frequência**: O tempo entre as compras, representado pela distância entre os círculos em uma única linha.\n",
    "* **Monetary**: a quantia de dinheiro gasta em cada compra, representada pelo tamanho do círculo. Esse valor pode ser o valor médio do pedido ou a quantidade de produtos que o cliente solicitou."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d46a1982",
   "metadata": {},
   "source": [
    "## Configurações"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "dc29eb23",
   "metadata": {},
   "source": [
    "### Definição de constantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd4c2e53",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adicione as dependências da biblioteca instalada à variável Python PATH.\n",
    "PATH=%env PATH\n",
    "%env PATH={PATH}:/home/jupyter/.local/bin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ead7a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recupere e defina as variáveis de ambiente PROJECT_ID e REGION.\n",
    "PROJECT_ID = !(gcloud config get-value core/project)\n",
    "PROJECT_ID = PROJECT_ID[0]\n",
    "REGION = 'us-central1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d6d4df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crie um bucket globalmente exclusivo do Google Cloud Storage para armazenamento de artefatos.\n",
    "GCS_BUCKET = f\"{PROJECT_ID}-bucket\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "883ab23c",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gsutil mb -l $REGION gs://$GCS_BUCKET"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8018cc87",
   "metadata": {},
   "source": [
    "### Importar bibliotecas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "412ffc51",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from google.cloud import aiplatform"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "aecf21cb",
   "metadata": {},
   "source": [
    "### Inicialize o cliente Vertex Python SDK"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a301853d",
   "metadata": {},
   "source": [
    "Importe o Vertex SDK for Python para seu ambiente Python e inicialize-o."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6029df",
   "metadata": {},
   "outputs": [],
   "source": [
    "aiplatform.init(project=PROJECT_ID, location=REGION, staging_bucket=f\"gs://{GCS_BUCKET}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cf880707",
   "metadata": {},
   "source": [
    "## Baixe e processe os dados do laboratório no BigQuery"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "742ceefd",
   "metadata": {},
   "source": [
    "### Conjunto de dados\n",
    "\n",
    "Neste laboratório, você usará o [conjunto de dados de varejo on-line] disponível publicamente (https://archive.ics.uci.edu/ml/datasets/online+retail) do UCI Machine Learning Repository. Este conjunto de dados contém 541.909 transações transnacionais de clientes ocorrendo entre (AAAA-MM-DD) 2010-12-01 e 2011-12-09 para um varejista sem loja registrado e baseado no Reino Unido. A empresa vende principalmente presentes exclusivos para todas as ocasiões. Muitos dos clientes da empresa são atacadistas.\n",
    "\n",
    "**Citação**\n",
    "Dua, D. e Karra Taniskidou, E. (2017). UCI Machine Learning Repository http://archive.ics.uci.edu/ml. Irvine, CA: Universidade da Califórnia, Escola de Informação e Ciência da Computação.\n",
    "\n",
    "Este laboratório também é inspirado na série de guias do arquiteto do Google Cloud [Prevendo o valor da vida útil do cliente com AI Platform: introdução](https://cloud.google.com/architecture/clv-prediction-with-offline-training-intro)."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c7d9d01",
   "metadata": {},
   "source": [
    "### Ingestão de dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "df4efbb9",
   "metadata": {},
   "source": [
    "Execute o comando abaixo para ingerir os dados do laboratório do repositório UCI Machine Learning no `Cloud Storage` e, em seguida, faça o upload para o `BigQuery` para processamento de dados. Os scripts de ingestão e processamento de dados estão disponíveis na pasta `utils` no diretório lab."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7720d05e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# constantes do BigQuery. Por favor, deixe-os inalterados.\n",
    "BQ_DATASET_NAME=\"online_retail\"\n",
    "BQ_RAW_TABLE_NAME=\"online_retail_clv_raw\"\n",
    "BQ_CLEAN_TABLE_NAME=\"online_retail_clv_clean\"\n",
    "BQ_ML_TABLE_NAME=\"online_retail_clv_ml\"\n",
    "BQ_URI=f\"bq://{PROJECT_ID}.{BQ_DATASET_NAME}.{BQ_ML_TABLE_NAME}\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "557df7b2",
   "metadata": {},
   "source": [
    "**Observação**: este script Python levará cerca de 2 a 3 minutos para baixar e processar o arquivo de dados do laboratório. Siga junto com a saída de registro na célula abaixo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a42e87bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "!python utils/data_download.py \\\n",
    "  --PROJECT_ID={PROJECT_ID} \\\n",
    "  --GCS_BUCKET={GCS_BUCKET} \\\n",
    "  --BQ_RAW_TABLE_NAME={BQ_RAW_TABLE_NAME} \\\n",
    "  --BQ_CLEAN_TABLE_NAME={BQ_CLEAN_TABLE_NAME} \\\n",
    "  --BQ_ML_TABLE_NAME={BQ_ML_TABLE_NAME} \\\n",
    "  --URL=\"https://archive.ics.uci.edu/ml/machine-learning-databases/00352/Online Retail.xlsx\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6ca57a9f",
   "metadata": {},
   "source": [
    "### Processamento de Dados"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c7293fc2",
   "metadata": {},
   "source": [
    "Como é o caso de muitos conjuntos de dados do mundo real, o conjunto de dados do laboratório exigiu alguma limpeza para você utilizar esses dados históricos de transações do cliente para CLV preditivo.\n",
    "\n",
    "As seguintes alterações foram aplicadas:\n",
    "\n",
    "* Mantenha apenas registros que tenham um ID de cliente.\n",
    "* Transações agregadas por dia a partir de faturas.\n",
    "* Mantenha apenas registros que tenham quantidades de pedidos e valores monetários positivos.\n",
    "* Agregue transações por ID do cliente e calcule a atualidade, a frequência, os recursos monetários, bem como a meta de previsão.\n",
    "\n",
    "**Características**:\n",
    "- `customer_country` (CATEGÓRICO): país de compra do cliente.\n",
    "- `n_purchases` (NUMERIC): quantidade de compras realizadas na janela de funcionalidades. (frequência)\n",
    "- `avg_purchase_size` (NUMERIC): contagem média de compra de unidades na janela de recursos. (monetário)\n",
    "- `avg_purchase_revenue` (NUMERIC): valor médio de compra em GBP na janela de recursos. (monetário)\n",
    "- `customer_age` (NUMERIC): dias a partir da primeira compra na janela de recursos.\n",
    "- `days_since_last_purchase` (NUMERIC): dias a partir da compra mais recente na janela de recursos. (recência)\n",
    "\n",
    "**Alvo**:\n",
    "- `target_monetary_value_3M` (NUMERIC): receita do cliente de toda a janela de estudo, incluindo recursos e janelas de previsão.\n",
    "\n",
    "Observação: este laboratório demonstra uma maneira simples de usar um DNN para prever o valor monetário CLV do cliente três meses à frente com base apenas no histórico de transações históricas do conjunto de dados disponível. Fatores adicionais a serem considerados na prática ao usar o CLV para informar as intervenções incluem custos de aquisição do cliente, margens de lucro e taxas de desconto para chegar ao valor presente dos fluxos de caixa futuros do cliente. Um dos benefícios de uma DNN em relação às abordagens tradicionais de modelagem probabilística é sua capacidade de incorporar recursos categóricos e não estruturados adicionais; esta é uma grande oportunidade de engenharia de recursos para explorar além deste laboratório, que apenas explora os recursos numéricos RFM."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "402abff6",
   "metadata": {},
   "source": [
    "## Análise exploratória de dados (EDA) no BigQuery"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f4fa4d6c",
   "metadata": {},
   "source": [
    "Abaixo, você usará o BigQuery deste notebook para fazer análises exploratórias de dados para conhecer esse conjunto de dados e identificar oportunidades para limpeza de dados e engenharia de recursos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91c50cbe",
   "metadata": {},
   "source": [
    "### Recência: há quanto tempo os clientes compraram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50110392",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery recency\n",
    "\n",
    "SELECT \n",
    "  days_since_last_purchase\n",
    "FROM \n",
    "  `online_retail.online_retail_clv_ml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75edeba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "recency.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bc69b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "recency.hist(bins=100);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e857fb43",
   "metadata": {},
   "source": [
    "No gráfico, há claramente alguns grupos de clientes diferentes aqui, como clientes fiéis que fizeram compras nos últimos dias, bem como clientes inativos que não compram há mais de 250 dias. Usando previsões e insights de CLV, você pode criar estratégias de marketing e intervenções promocionais para melhorar a recência da compra do cliente e reativar clientes inativos."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d4d8860",
   "metadata": {},
   "source": [
    "### Frequência: com que frequência os clientes compram?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34402015",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery frequency\n",
    "\n",
    "SELECT\n",
    "  n_purchases\n",
    "FROM\n",
    "  `online_retail.online_retail_clv_ml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1fd5c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cbeac7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "frequency.hist(bins=100);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00c933f5",
   "metadata": {},
   "source": [
    "No gráfico e nos quantis, você pode ver que metade dos clientes tem menos ou igual a apenas 2 compras. Você também pode dizer pelas compras médias > compras medianas e compras máximas de 81 que existem clientes, provavelmente atacadistas, que fizeram significativamente mais compras. Isso deve fazer com que você já esteja pensando em oportunidades de engenharia de recursos, como segmentação de compras e remoção ou recorte de clientes atípicos. Você também pode explorar estratégias de modelagem alternativas para CLV em novos clientes que fizeram apenas uma compra, pois a abordagem demonstrada neste laboratório terá um desempenho melhor em clientes com mais histórico de transações de relacionamento."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "00c0c043",
   "metadata": {},
   "source": [
    "### Monetário: quanto os clientes estão gastando?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b8d00ea",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery monetary\n",
    "\n",
    "SELECT\n",
    "  target_monetary_value_3M\n",
    "FROM\n",
    "`online_retail.online_retail_clv_ml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636a5010",
   "metadata": {},
   "outputs": [],
   "source": [
    "monetary.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08b651c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "monetary['target_monetary_value_3M'].plot(kind='box', title=\"Target Monetary Value 3M: wide range, long right tail distribution\", grid=True);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7bc60b98",
   "metadata": {},
   "source": [
    "No gráfico e nas estatísticas resumidas, você pode ver que há uma ampla variação no valor monetário do cliente, variando de 2,90 a 268.478 libras esterlinas. Olhando para os quantis, fica claro que existem alguns clientes atípicos cujo valor monetário é maior que 3 desvios padrão da média. Com esse pequeno conjunto de dados, é recomendável remover esses valores discrepantes do cliente para tratá-los separadamente, alterar a função de perda do seu modelo para ser mais resistente a discrepâncias, registrar o recurso de destino ou recortar seus valores para um limite máximo. Você também deve revisar seus requisitos de negócios CLV para ver se o valor monetário do cliente e reenquadrar isso como um problema de classificação de ML atenderia às suas necessidades."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02e553fd",
   "metadata": {},
   "source": [
    "### Estabeleça uma linha de base de desempenho de modelo simples"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08221502",
   "metadata": {},
   "source": [
    "Para avaliar o desempenho de seu modelo TensorFlow DNN Regressor personalizado que você criará nas próximas etapas, é uma prática recomendada de ML estabelecer uma linha de base de desempenho simples. Abaixo está uma linha de base SQL simples que multiplica o gasto médio de compra de um cliente composto por sua taxa de compra diária e calcula métricas de regressão padrão."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf088864",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "WITH\n",
    "  day_intervals AS (\n",
    "  SELECT\n",
    "      customer_id,\n",
    "      DATE_DIFF(DATE('2011-12-01'), DATE('2011-09-01'), DAY) AS target_days,\n",
    "      DATE_DIFF(DATE('2011-09-01'), MIN(order_date), DAY) AS feature_days,\n",
    "  FROM\n",
    "    `online_retail.online_retail_clv_clean`\n",
    "  GROUP BY\n",
    "      customer_id\n",
    "  ),\n",
    "    \n",
    "  predicted_clv AS (\n",
    "  SELECT\n",
    "      customer_id,\n",
    "      AVG(avg_purchase_revenue) * (COUNT(n_purchases) * (1 + SAFE_DIVIDE(COUNT(target_days),COUNT(feature_days)))) AS predicted_monetary_value_3M,\n",
    "      SUM(target_monetary_value_3M) AS target_monetary_value_3M\n",
    "  FROM\n",
    "    `online_retail.online_retail_clv_ml`\n",
    "  LEFT JOIN day_intervals USING(customer_id)\n",
    "  GROUP BY\n",
    "      customer_id\n",
    "  )\n",
    "\n",
    "# Calcule métricas gerais de regressão linear\n",
    "SELECT\n",
    "  ROUND(AVG(ABS(predicted_monetary_value_3M - target_monetary_value_3M)), 2) AS MAE,\n",
    "  ROUND(AVG(POW(predicted_monetary_value_3M - target_monetary_value_3M, 2)), 2) AS MSE,\n",
    "  ROUND(SQRT(AVG(POW(predicted_monetary_value_3M - target_monetary_value_3M, 2))), 2) AS RMSE\n",
    "FROM\n",
    "  predicted_clv"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "956ac010",
   "metadata": {},
   "source": [
    "Esses resultados da linha de base fornecem suporte adicional para o forte impacto dos valores discrepantes. O MSE extremamente alto vem da penalidade exponencial aplicada a previsões perdidas e da magnitude do erro em algumas previsões.\n",
    "\n",
    "Em seguida, você deve traçar os resultados da linha de base para ter uma noção das áreas de oportunidade para seu modelo de ML."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e14ff67",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery baseline\n",
    "\n",
    "WITH\n",
    "  day_intervals AS (\n",
    "  SELECT\n",
    "      customer_id,\n",
    "      DATE_DIFF(DATE('2011-12-01'), DATE('2011-09-01'), DAY) AS target_days,\n",
    "      DATE_DIFF(DATE('2011-09-01'), MIN(order_date), DAY) AS feature_days,\n",
    "  FROM\n",
    "    `online_retail.online_retail_clv_clean`\n",
    "  GROUP BY\n",
    "      customer_id\n",
    "  ),\n",
    "    \n",
    "  predicted_clv AS (\n",
    "  SELECT\n",
    "      customer_id,\n",
    "      AVG(avg_purchase_revenue) * (COUNT(n_purchases) * (1 + SAFE_DIVIDE(COUNT(target_days),COUNT(feature_days)))) AS predicted_monetary_value_3M,\n",
    "      SUM(target_monetary_value_3M) AS target_monetary_value_3M\n",
    "  FROM\n",
    "    `online_retail.online_retail_clv_ml`\n",
    "  INNER JOIN day_intervals USING(customer_id)\n",
    "  GROUP BY\n",
    "      customer_id\n",
    "  )\n",
    "\n",
    "SELECT\n",
    " *\n",
    "FROM\n",
    "  predicted_clv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afda73aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "baseline.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a543c10",
   "metadata": {},
   "outputs": [],
   "source": [
    "ax = baseline.plot(kind='scatter',\n",
    "                   x='predicted_monetary_value_3M', \n",
    "                   y='target_monetary_value_3M',\n",
    "                   title='Actual vs. Predicted customer 3-month monetary value',\n",
    "                   figsize=(5,5),\n",
    "                   grid=True)\n",
    "\n",
    "lims = [\n",
    "    np.min([ax.get_xlim(), ax.get_ylim()]),  # min of both axes\n",
    "    np.max([ax.get_xlim(), ax.get_ylim()]),  # max of both axes\n",
    "]\n",
    "\n",
    "# now plot both limits against eachother\n",
    "ax.plot(lims, lims, 'k-', alpha=0.5, zorder=0)\n",
    "ax.set_aspect('equal')\n",
    "ax.set_xlim(lims)\n",
    "ax.set_ylim(lims);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0d53ad3a",
   "metadata": {},
   "source": [
    "## Treine um modelo do TensorFlow localmente"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b3658b32",
   "metadata": {},
   "source": [
    "Agora que você tem uma linha de base simples para comparar seu desempenho, treine um TensorFlow Regressor para prever o CLV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c45e2feb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery\n",
    "\n",
    "SELECT data_split, COUNT(*)\n",
    "FROM `online_retail.online_retail_clv_ml`\n",
    "GROUP BY data_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7e2994a",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%bigquery clv\n",
    "\n",
    "SELECT *\n",
    "FROM `online_retail.online_retail_clv_ml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80339852",
   "metadata": {},
   "outputs": [],
   "source": [
    "clv_train = clv.loc[clv.data_split == 'TRAIN', :]\n",
    "clv_dev = clv.loc[clv.data_split == 'VALIDATE', :]\n",
    "clv_test = clv.loc[clv.data_split == 'TEST', :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a15e9683",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constantes de treinamento do modelo.\n",
    "# Padrão de design de épocas virtuais:\n",
    "# https://medium.com/google-cloud/ml-design-pattern-3-virtual-epochs-f842296de730\n",
    "N_TRAIN_EXAMPLES = 2638\n",
    "STOP_POINT = 20.0\n",
    "TOTAL_TRAIN_EXAMPLES = int(STOP_POINT * N_TRAIN_EXAMPLES)\n",
    "BATCH_SIZE = 32\n",
    "N_CHECKPOINTS = 10\n",
    "STEPS_PER_EPOCH = (TOTAL_TRAIN_EXAMPLES // (BATCH_SIZE*N_CHECKPOINTS))\n",
    "\n",
    "NUMERIC_FEATURES = [\n",
    "    \"n_purchases\",\n",
    "    \"avg_purchase_size\",\n",
    "    \"avg_purchase_revenue\",\n",
    "    \"customer_age\",\n",
    "    \"days_since_last_purchase\",\n",
    "]\n",
    "\n",
    "LABEL = \"target_monetary_value_3M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "627cc31a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def df_dataset(df):\n",
    "    \"\"\"Transform Pandas Dataframe to TensorFlow Dataset.\"\"\"\n",
    "    return tf.data.Dataset.from_tensor_slices((df[NUMERIC_FEATURES].to_dict('list'), df[LABEL].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b0744b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainds = df_dataset(clv_train).prefetch(1).batch(BATCH_SIZE).repeat()\n",
    "devds = df_dataset(clv_dev).prefetch(1).batch(BATCH_SIZE)\n",
    "testds = df_dataset(clv_test).prefetch(1).batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9459079",
   "metadata": {},
   "outputs": [],
   "source": [
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Custom RMSE regression metric.\"\"\"\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "def build_model():\n",
    "    \"\"\"Build and compile a TensorFlow Keras Regressor.\"\"\"\n",
    "    # Defina tensores de recursos de entrada e camadas de entrada.\n",
    "    feature_columns = [\n",
    "        tf.feature_column.numeric_column(key=feature)\n",
    "        for feature in NUMERIC_FEATURES\n",
    "    ]\n",
    "    \n",
    "    input_layers = {\n",
    "        feature.key: tf.keras.layers.Input(name=feature.key, shape=(), dtype=tf.float32)\n",
    "        for feature in feature_columns\n",
    "    }\n",
    "     \n",
    "    # Keras Functional API: https://keras.io/guides/functional_api\n",
    "    inputs = tf.keras.layers.DenseFeatures(feature_columns, name='inputs')(input_layers)\n",
    "    d1 = tf.keras.layers.Dense(256, activation=tf.nn.relu, name='d1')(inputs)\n",
    "    d2 = tf.keras.layers.Dropout(0.2, name='d2')(d1)  \n",
    "    # Nota: a saída de um único neurônio para regressão.\n",
    "    output = tf.keras.layers.Dense(1, name='output')(d2)\n",
    "    \n",
    "    model = tf.keras.Model(input_layers, output, name='online-retail-clv')\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(0.001)    \n",
    "    \n",
    "    # Note: A perda de MAE é mais resistente a valores discrepantes do que MSE.\n",
    "    model.compile(loss=tf.keras.losses.MAE,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[['mae', 'mse', rmse]])\n",
    "    \n",
    "    return model\n",
    "\n",
    "model = build_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8601ff5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "tf.keras.utils.plot_model(model, show_shapes=True, rankdir=\"LR\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354206ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "    log_dir='./local-training/tensorboard',\n",
    "    histogram_freq=1)\n",
    "\n",
    "earlystopping_callback = tf.keras.callbacks.EarlyStopping(patience=1)\n",
    "\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    filepath='./local-training/checkpoints',\n",
    "    save_weights_only=True,\n",
    "    monitor='val_loss',\n",
    "    mode='min')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730181fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(trainds,\n",
    "                    validation_data=devds,\n",
    "                    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                    epochs=N_CHECKPOINTS,\n",
    "                    callbacks=[[tensorboard_callback,\n",
    "                                earlystopping_callback,\n",
    "                                checkpoint_callback]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2594d084",
   "metadata": {},
   "outputs": [],
   "source": [
    "LOSS_COLS = [\"loss\", \"val_loss\"]\n",
    "\n",
    "pd.DataFrame(history.history)[LOSS_COLS].plot();"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71775db",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_pred = model.predict(df_dataset(clv_train).prefetch(1).batch(BATCH_SIZE))\n",
    "dev_pred = model.predict(devds)\n",
    "test_pred = model.predict(testds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b6eceb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_results = pd.DataFrame({'actual': clv_train['target_monetary_value_3M'].to_numpy(), 'predicted': np.squeeze(train_pred)}, columns=['actual', 'predicted'])\n",
    "dev_results = pd.DataFrame({'actual': clv_dev['target_monetary_value_3M'].to_numpy(), 'predicted': np.squeeze(dev_pred)}, columns=['actual', 'predicted'])\n",
    "test_results = pd.DataFrame({'actual': clv_test['target_monetary_value_3M'].to_numpy(), 'predicted': np.squeeze(test_pred)}, columns=['actual', 'predicted'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4659dd09",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Gráficos de calibração de previsão de modelo.\n",
    "fig, (train_ax, dev_ax, test_ax) = plt.subplots(1, 3, figsize=(15,15))\n",
    "\n",
    "train_results.plot(kind='scatter',\n",
    "                  x='predicted',\n",
    "                  y='actual',\n",
    "                  title='Train: act vs. pred customer 3M monetary value',\n",
    "                  grid=True,\n",
    "                  ax=train_ax)\n",
    "\n",
    "train_lims = [\n",
    "    np.min([train_ax.get_xlim(), train_ax.get_ylim()]),  # min de ambos os eixos\n",
    "    np.max([train_ax.get_xlim(), train_ax.get_ylim()]),  # max de ambos os eixos\n",
    "]\n",
    "\n",
    "train_ax.plot(train_lims, train_lims, 'k-', alpha=0.5, zorder=0)\n",
    "train_ax.set_aspect('equal')\n",
    "train_ax.set_xlim(train_lims)\n",
    "train_ax.set_ylim(train_lims)\n",
    "\n",
    "dev_results.plot(kind='scatter',\n",
    "                  x='predicted',\n",
    "                  y='actual',\n",
    "                  title='Dev: act vs. pred customer 3M monetary value',\n",
    "                  grid=True,\n",
    "                  ax=dev_ax)\n",
    "\n",
    "dev_lims = [\n",
    "    np.min([dev_ax.get_xlim(), dev_ax.get_ylim()]),  # min de ambos os eixos\n",
    "    np.max([dev_ax.get_xlim(), dev_ax.get_ylim()]),  # max de ambos os eixos\n",
    "]\n",
    "\n",
    "dev_ax.plot(dev_lims, dev_lims, 'k-', alpha=0.5, zorder=0)\n",
    "dev_ax.set_aspect('equal')\n",
    "dev_ax.set_xlim(dev_lims)\n",
    "dev_ax.set_ylim(dev_lims)\n",
    "\n",
    "test_results.plot(kind='scatter',\n",
    "                  x='predicted',\n",
    "                  y='actual',\n",
    "                  title='Test: act vs. pred customer 3M monetary value',\n",
    "                  grid=True,\n",
    "                  ax=test_ax)\n",
    "\n",
    "test_lims = [\n",
    "    np.min([test_ax.get_xlim(), test_ax.get_ylim()]),  # min de ambos os eixos\n",
    "    np.max([test_ax.get_xlim(), test_ax.get_ylim()]),  # max de ambos os eixos\n",
    "]\n",
    "\n",
    "test_ax.plot(test_lims, test_lims, 'k-', alpha=0.5, zorder=0)\n",
    "test_ax.set_aspect('equal')\n",
    "test_ax.set_xlim(test_lims)\n",
    "test_ax.set_ylim(test_lims);"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2a5f1582",
   "metadata": {},
   "source": [
    "Você treinou um modelo melhor do que sua linha de base. Conforme indicado nos gráficos acima, ainda há oportunidades adicionais de engenharia de recursos e limpeza de dados para melhorar o desempenho do seu modelo em clientes com CLV. Algumas opções incluem lidar com esses clientes como uma tarefa de previsão separada, aplicar uma transformação de log ao seu destino, recortar seu valor ou descartar esses clientes todos juntos para melhorar o desempenho do modelo.\n",
    "\n",
    "Agora você trabalhará levando esse fluxo de trabalho local do TensorFlow para a nuvem com a Vertex AI."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "24bb7c43",
   "metadata": {},
   "source": [
    "## Crie um conjunto de dados tabular gerenciado de sua fonte de dados do BigQuery"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f8383baa",
   "metadata": {},
   "source": [
    "[**Conjuntos de dados gerenciados da Vertex AI**](https://cloud.google.com/vertex-ai/docs/datasets/prepare-tabular) podem ser usados para treinar modelos AutoML ou modelos treinados personalizados.\n",
    "\n",
    "Você criará um [**conjunto de dados de regressão tabular**](https://cloud.google.com/vertex-ai/docs/datasets/bp-tabular) para gerenciar o compartilhamento e os metadados do conjunto de dados deste laboratório armazenado no BigQuery. Conjuntos de dados gerenciados permitem que você crie um vínculo claro entre seus dados e modelos treinados personalizados e forneça estatísticas descritivas e divisão automática ou manual em conjuntos de treinamento, teste e validação.\n",
    "\n",
    "Neste laboratório, a etapa de processamento de dados já criou uma coluna `data_split` manual em nossa tabela BQ ML usando [funções de hash do BigQuery](https://towardsdatascience.com/ml-design-pattern-5-repeatable-sampling-c0ccb2889f39) para amostragem repetível."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "964c1eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tabular_dataset = aiplatform.TabularDataset.create(display_name=\"online-retail-clv\", bq_source=f\"{BQ_URI}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "420b6fd9",
   "metadata": {},
   "source": [
    "## Fluxo de trabalho de treinamento de modelo de ML personalizado da Vertex AI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c3806a39",
   "metadata": {},
   "source": [
    "Há duas maneiras de treinar um modelo personalizado na Vertex AI:\n",
    "\n",
    "Antes de enviar um trabalho de treinamento personalizado, um trabalho de ajuste de hiperparâmetros ou um pipeline de treinamento para a Vertex AI, você precisa criar um aplicativo de treinamento em Python ou um contêiner personalizado para definir o código de treinamento e as dependências que deseja executar na Vertex AI.\n",
    "\n",
    "**1. Use um contêiner predefinido do Google Cloud**: se você usar um contêiner predefinido do Vertex AI, escreverá um script Python `task.py` ou um pacote Python para instalar na imagem do contêiner que define seu código para treinar um modelo personalizado. Consulte [Creating a Python training application for a pre-built container](https://cloud.google.com/vertex-ai/docs/training/create-python-pre-built-container) para obter mais detalhes sobre como estruturar seu código Python. Escolha esta opção se um contêiner pré-criado já contiver as bibliotecas de treinamento de modelo de que você precisa, como `tensorflow` ou `xgboost`, e você estiver apenas fazendo treinamento e previsão de ML rapidamente. Você também pode especificar dependências adicionais do Python para instalar por meio do argumento `CustomTrainingJob(requirements=...`).\n",
    "\n",
    "**2. Use sua própria imagem de contêiner personalizada**: se quiser usar seu próprio contêiner personalizado, você escreverá seus scripts de treinamento Python e um Dockerfile que contém instruções sobre seu código de modelo de ML, dependências e instruções de execução. Você criará seu contêiner personalizado com o Cloud Build, cujas instruções são especificadas em `cloudbuild.yaml` e publicará seu contêiner no Artifact Registry. Escolha esta opção se quiser empacotar seu código de modelo de ML com dependências em um contêiner para criar a execução como parte de um [Vertex Pipelines] portátil e escalonável (https://cloud.google.com/vertex-ai/docs/pipelines/introdução) fluxo de trabalho."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2e42f26a",
   "metadata": {},
   "source": [
    "### Conteinerize seu código de treinamento de modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "6b99d903",
   "metadata": {},
   "source": [
    "Nas próximas 5 etapas, você prosseguirá com **2. Use sua própria imagem de contêiner personalizada**.\n",
    "\n",
    "Você criará seu contêiner de modelo personalizado sobre um [contêiner de aprendizagem profunda do Google Cloud](https://cloud.google.com/vertex-ai/docs/general/deep-learning) que contém versões testadas e otimizadas do código do modelo dependências como `tensorflow` e o SDK `google-cloud-bigquery`. Isso também oferece flexibilidade e permite gerenciar e compartilhar sua imagem de contêiner de modelo com outras pessoas para reutilização e reprodutibilidade em ambientes, além de permitir que você incorpore pacotes adicionais para seu aplicativo de ML. Por fim, ao empacotar seu código de modelo de ML junto com as dependências, você também tem um caminho de integração MLOps para o Vertex Pipelines.\n",
    "\n",
    "Você passará pela criação da seguinte estrutura de projeto para seu código de modo ML:\n",
    "\n",
    "```\n",
    "|--/online-retail-clv-3M\n",
    "   |--/trainer\n",
    "      |--__init__.py\n",
    "      |--model.py\n",
    "      |--task.py\n",
    "   |--Dockerfile\n",
    "   |--cloudbuild.yaml\n",
    "   |--requirements.txt\n",
    "```"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2db0ba26",
   "metadata": {},
   "source": [
    "#### 1. Escreva um script de treinamento `model.py`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "cb5a08e3",
   "metadata": {},
   "source": [
    "Primeiro, você organizará o código de treinamento do modelo TensorFlow local acima em um script de treinamento.\n",
    "\n",
    "A maior mudança é que você utilizará a biblioteca [TensorFlow IO](https://www.tensorflow.org/io/tutorials/bigquery) para ler com desempenho do BigQuery diretamente no gráfico do modelo do TensorFlow durante o treinamento. Isso melhorará seu desempenho de treinamento em vez de executar a etapa intermediária de leitura do BigQuery em um Pandas Dataframe feito para conveniência acima."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0cae846",
   "metadata": {},
   "outputs": [],
   "source": [
    "# este é o nome do subdiretório do modelo no qual você escreverá o código do modelo. Ele já está criado no diretório do seu laboratório.\n",
    "MODEL_NAME=\"online-retail-clv-3M\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbe19974",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {MODEL_NAME}/trainer/model.py\n",
    "import os\n",
    "import logging\n",
    "import tempfile\n",
    "import tensorflow as tf\n",
    "from explainable_ai_sdk.metadata.tf.v2 import SavedModelMetadataBuilder\n",
    "from tensorflow.python.framework import dtypes\n",
    "from tensorflow_io.bigquery import BigQueryClient\n",
    "from tensorflow_io.bigquery import BigQueryReadSession\n",
    "\n",
    "\n",
    "# Constantes de recursos do modelo.\n",
    "NUMERIC_FEATURES = [\n",
    "    \"n_purchases\",\n",
    "    \"avg_purchase_size\",\n",
    "    \"avg_purchase_revenue\",\n",
    "    \"customer_age\",\n",
    "    \"days_since_last_purchase\",\n",
    "]\n",
    "\n",
    "CATEGORICAL_FEATURES = [\n",
    "    \"customer_country\"\n",
    "]\n",
    "\n",
    "LABEL = \"target_monetary_value_3M\"\n",
    "\n",
    "\n",
    "def caip_uri_to_fields(uri):\n",
    "    \"\"\"Helper function to parse BQ URI.\"\"\"\n",
    "    # Remova o prefixo bq://.\n",
    "    uri = uri[5:]\n",
    "    project, dataset, table = uri.split('.')\n",
    "    return project, dataset, table\n",
    "\n",
    "\n",
    "def features_and_labels(row_data):\n",
    "    \"\"\"Helper feature and label mapping function for tf.data.\"\"\"\n",
    "    label = row_data.pop(LABEL)\n",
    "    features = row_data\n",
    "    return features, label\n",
    "\n",
    "\n",
    "def read_bigquery(project, dataset, table):\n",
    "    \"\"\"TensorFlow IO BigQuery Reader.\"\"\"\n",
    "    tensorflow_io_bigquery_client = BigQueryClient()\n",
    "    read_session = tensorflow_io_bigquery_client.read_session(\n",
    "      parent=\"projects/\" + project,\n",
    "      project_id=project, \n",
    "      dataset_id=dataset,\n",
    "      table_id=table,\n",
    "      # Passe a lista de recursos e rótulos a serem selecionados no BQ.\n",
    "      selected_fields=NUMERIC_FEATURES + [LABEL],\n",
    "     # Forneça tipos de dados TensorFlow de saída para recursos e rótulos.\n",
    "      output_types=[dtypes.int64, dtypes.float64, dtypes.float64, dtypes.int64, dtypes.int64] + [dtypes.float64],\n",
    "      requested_streams=2)\n",
    "    dataset = read_session.parallel_read_rows()\n",
    "    transformed_ds = dataset.map(features_and_labels)\n",
    "    return transformed_ds\n",
    "\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    \"\"\"Custom RMSE regression metric.\"\"\"\n",
    "    return tf.sqrt(tf.reduce_mean(tf.square(y_pred - y_true)))\n",
    "\n",
    "\n",
    "def build_model(hparams):\n",
    "    \"\"\"Build and compile a TensorFlow Keras DNN Regressor.\"\"\"\n",
    "\n",
    "    feature_columns = [\n",
    "        tf.feature_column.numeric_column(key=feature)\n",
    "        for feature in NUMERIC_FEATURES\n",
    "    ]\n",
    "    \n",
    "    input_layers = {\n",
    "        feature.key: tf.keras.layers.Input(name=feature.key, shape=(), dtype=tf.float32)\n",
    "        for feature in feature_columns\n",
    "    }\n",
    "    # Keras Functional API: https://keras.io/guides/functional_api\n",
    "    inputs = tf.keras.layers.DenseFeatures(feature_columns, name='inputs')(input_layers)\n",
    "    d1 = tf.keras.layers.Dense(256, activation=tf.nn.relu, name='d1')(inputs)\n",
    "    d2 = tf.keras.layers.Dropout(hparams['dropout'], name='d2')(d1)    \n",
    "    #Nota: uma saída escalar de um único neurônio para regressão.\n",
    "    output = tf.keras.layers.Dense(1, name='output')(d2)\n",
    "    \n",
    "    model = tf.keras.Model(input_layers, output, name='online-retail-clv')\n",
    "    \n",
    "    optimizer = tf.keras.optimizers.Adam(hparams['learning-rate'])    \n",
    "    \n",
    "    # Observação: a perda de MAE é mais resistente a valores discrepantes do que MSE.\n",
    "    model.compile(loss=tf.keras.losses.MAE,\n",
    "                  optimizer=optimizer,\n",
    "                  metrics=[['mae', 'mse', rmse]])\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "def train_evaluate_explain_model(hparams):\n",
    "    \"\"\"Train, evaluate, explain TensorFlow Keras DNN Regressor.\n",
    "    Args:\n",
    "      hparams(dict): A dictionary containing model training arguments.\n",
    "    Returns:\n",
    "      history(tf.keras.callbacks.History): Keras callback that records training event history.\n",
    "    \"\"\"\n",
    "    training_ds = read_bigquery(*caip_uri_to_fields(hparams['training-data-uri'])).prefetch(1).shuffle(hparams['batch-size']*10).batch(hparams['batch-size']).repeat()\n",
    "    eval_ds = read_bigquery(*caip_uri_to_fields(hparams['validation-data-uri'])).prefetch(1).shuffle(hparams['batch-size']*10).batch(hparams['batch-size'])\n",
    "    test_ds = read_bigquery(*caip_uri_to_fields(hparams['test-data-uri'])).prefetch(1).shuffle(hparams['batch-size']*10).batch(hparams['batch-size'])\n",
    "    \n",
    "    model = build_model(hparams)\n",
    "    logging.info(model.summary())\n",
    "    \n",
    "    tensorboard_callback = tf.keras.callbacks.TensorBoard(\n",
    "        log_dir=hparams['tensorboard-dir'],\n",
    "        histogram_freq=1)\n",
    "    \n",
    "    # Reduza o overfitting e diminua os tempos de treinamento.\n",
    "    earlystopping_callback = tf.keras.callbacks.EarlyStopping(patience=2)\n",
    "    \n",
    "    #Garanta a resiliência do seu trabalho de treinamento para reinicializações de VM.\n",
    "    checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "        filepath= hparams['checkpoint-dir'],\n",
    "        save_weights_only=True,\n",
    "        monitor='val_loss',\n",
    "        mode='min')\n",
    "    \n",
    "    # Padrão de design de épocas virtuais:\n",
    "    # https://medium.com/google-cloud/ml-design-pattern-3-virtual-epochs-f842296de730\n",
    "    TOTAL_TRAIN_EXAMPLES = int(hparams['stop-point'] * hparams['n-train-examples'])\n",
    "    STEPS_PER_EPOCH = (TOTAL_TRAIN_EXAMPLES // (hparams['batch-size']*hparams['n-checkpoints']))    \n",
    "    \n",
    "    history = model.fit(training_ds,\n",
    "                        validation_data=eval_ds,\n",
    "                        steps_per_epoch=STEPS_PER_EPOCH,\n",
    "                        epochs=hparams['n-checkpoints'],\n",
    "                        callbacks=[[tensorboard_callback,\n",
    "                                    earlystopping_callback,\n",
    "                                    checkpoint_callback]])\n",
    "    \n",
    "    logging.info(model.evaluate(test_ds))\n",
    "    \n",
    "    # Crie um diretório temporário para salvar o TF SavedModel intermediário antes da criação de metadados Explainable.\n",
    "    tmpdir = tempfile.mkdtemp()\n",
    "    \n",
    "    # Exporte o modelo Keras no formato TensorFlow SavedModel.\n",
    "    model.save(tmpdir)\n",
    "    \n",
    "    #Anote e salve TensorFlow SavedModel com metadados Explainable no GCS.\n",
    "    builder = SavedModelMetadataBuilder(tmpdir)\n",
    "    builder.save_model_with_metadata(hparams['model-dir'])\n",
    "    \n",
    "    return history"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c10121ec",
   "metadata": {},
   "source": [
    "#### 2. Escreva um arquivo `task.py` como um ponto de entrada para seu contêiner de modelo de ML personalizado"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d4d6add",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {MODEL_NAME}/trainer/task.py\n",
    "import os\n",
    "import argparse\n",
    "\n",
    "from trainer import model\n",
    "\n",
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    # Argumentos de treinamento de contêiner personalizado da Vertex. Eles são definidos pela Vertex AI durante o treinamento, mas também podem ser substituídos.\n",
    "    parser.add_argument('--model-dir', dest='model-dir',\n",
    "                        default=os.environ['AIP_MODEL_DIR'], type=str, help='Model dir.')\n",
    "    parser.add_argument('--checkpoint-dir', dest='checkpoint-dir',\n",
    "                        default=os.environ['AIP_CHECKPOINT_DIR'], type=str, help='Checkpoint dir set during Vertex AI training.')    \n",
    "    parser.add_argument('--tensorboard-dir', dest='tensorboard-dir',\n",
    "                        default=os.environ['AIP_TENSORBOARD_LOG_DIR'], type=str, help='Tensorboard dir set during Vertex AI training.')    \n",
    "    parser.add_argument('--data-format', dest='data-format',\n",
    "                        default=os.environ['AIP_DATA_FORMAT'], type=str, help=\"Tabular data format set during Vertex AI training. E.g.'csv', 'bigquery'\")\n",
    "    parser.add_argument('--training-data-uri', dest='training-data-uri',\n",
    "                        default=os.environ['AIP_TRAINING_DATA_URI'], type=str, help='Training data GCS or BQ URI set during Vertex AI training.')\n",
    "    parser.add_argument('--validation-data-uri', dest='validation-data-uri',\n",
    "                        default=os.environ['AIP_VALIDATION_DATA_URI'], type=str, help='Validation data GCS or BQ URI set during Vertex AI training.')\n",
    "    parser.add_argument('--test-data-uri', dest='test-data-uri',\n",
    "                        default=os.environ['AIP_TEST_DATA_URI'], type=str, help='Test data GCS or BQ URI set during Vertex AI training.')\n",
    "    # Argumentos de treinamento do modelo.\n",
    "    parser.add_argument('--learning-rate', dest='learning-rate', default=0.001, type=float, help='Learning rate for optimizer.')\n",
    "    parser.add_argument('--dropout', dest='dropout', default=0.2, type=float, help='Float percentage of DNN nodes [0,1] to drop for regularization.')    \n",
    "    parser.add_argument('--batch-size', dest='batch-size', default=16, type=int, help='Number of examples during each training iteration.')    \n",
    "    parser.add_argument('--n-train-examples', dest='n-train-examples', default=2638, type=int, help='Number of examples to train on.')\n",
    "    parser.add_argument('--stop-point', dest='stop-point', default=10, type=int, help='Number of passes through the dataset during training to achieve convergence.')\n",
    "    parser.add_argument('--n-checkpoints', dest='n-checkpoints', default=10, type=int, help='Number of model checkpoints to save during training.')\n",
    "    \n",
    "    args = parser.parse_args()\n",
    "    hparams = args.__dict__\n",
    "\n",
    "    model.train_evaluate_explain_model(hparams)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "18058766",
   "metadata": {},
   "source": [
    "#### 3. Escreva um `Dockerfile` para seu contêiner de modelo de ML personalizado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "987cc52a",
   "metadata": {},
   "source": [
    "Em terceiro lugar, você escreverá um `Dockerfile` que contém o código do modelo, bem como especifica as dependências do código do modelo.\n",
    "\n",
    "Observe que a imagem base abaixo é um [contêiner Google Cloud Deep Learning](https://cloud.google.com/vertex-ai/docs/general/deep-learning) que contém versões testadas e otimizadas de dependências de código de modelo, como ` tensorflow` e o SDK `google-cloud-bigquery`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28ea8f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {MODEL_NAME}/Dockerfile\n",
    "# Specifies base image and tag.\n",
    "# https://cloud.google.com/vertex-ai/docs/general/deep-learning\n",
    "# https://cloud.google.com/deep-learning-containers/docs/choosing-container\n",
    "FROM gcr.io/deeplearning-platform-release/tf2-cpu.2-3\n",
    "\n",
    "# Define o diretório de trabalho do contêiner.\n",
    "WORKDIR /root\n",
    "\n",
    "# Copia o requirements.txt no contêiner para reduzir as chamadas de rede.\n",
    "COPY requirements.txt .\n",
    "# Installs additional packages.\n",
    "RUN pip3 install -U -r requirements.txt\n",
    "\n",
    "# Copia o código do treinador para a imagem do docker.\n",
    "COPY . /trainer\n",
    "\n",
    "# Define o diretório de trabalho do contêiner.\n",
    "WORKDIR /trainer\n",
    "\n",
    "# Define o diretório de trabalho do contêiner.\n",
    "ENTRYPOINT [\"python\", \"-m\", \"trainer.task\"]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f2db8aea",
   "metadata": {},
   "source": [
    "### 4. Escreva um arquivo `requirements.txt` para especificar dependências de código ML adicionais"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f13b99fb",
   "metadata": {},
   "source": [
    "Essas são dependências adicionais para o código do seu modelo fora dos contêineres de aprendizado profundo necessários para a explicabilidade da previsão e o leitor BigQuery TensorFlow IO."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06998a4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%writefile {MODEL_NAME}/requirements.txt\n",
    "explainable-ai-sdk==1.3.0\n",
    "tensorflow-io==0.15.0\n",
    "pyarrow"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "5214db92",
   "metadata": {},
   "source": [
    "#### 5. Use o Cloud Build para criar e enviar seu contêiner para o Google Cloud Artifact Registry"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "25ff06d2",
   "metadata": {},
   "source": [
    "Em seguida, você usará o [Cloud Build](https://cloud.google.com/build) para criar e enviar seu contêiner de modelo personalizado do TensorFlow para o [Google Cloud Artifact Registry](https://cloud.google.com/artifact-registro).\n",
    "\n",
    "O Cloud Build traz reutilização e automação para sua experimentação de ML, permitindo que você crie, teste e implante de maneira confiável seu código de modelo de ML como parte de um fluxo de trabalho de CI/CD. O Artifact Registry fornece um repositório centralizado para você armazenar, gerenciar e proteger suas imagens de contêiner de ML. Isso permitirá que você compartilhe com segurança seu trabalho de ML com outras pessoas e reproduza os resultados do experimento.\n",
    "\n",
    "**Observação**: a etapa inicial de compilação e envio levará cerca de 20 minutos, mas o Cloud Build pode aproveitar o armazenamento em cache para compilações subsequentes."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "65a8c7f1",
   "metadata": {},
   "source": [
    "#### Criar repositório de artefatos para imagens de contêiner personalizadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8984969",
   "metadata": {},
   "outputs": [],
   "source": [
    "ARTIFACT_REPOSITORY=\"online-retail-clv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff4c1484",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an Artifact Repository using the gcloud CLI.\n",
    "!gcloud artifacts repositories create $ARTIFACT_REPOSITORY \\\n",
    "--repository-format=docker \\\n",
    "--location=$REGION \\\n",
    "--description=\"Artifact registry for ML custom training images for predictive CLV\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b8703d94",
   "metadata": {},
   "source": [
    "#### Criar instruções `cloudbuild.yaml`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efe17ff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "IMAGE_NAME=\"dnn-regressor\"\n",
    "IMAGE_TAG=\"latest\"\n",
    "IMAGE_URI=f\"{REGION}-docker.pkg.dev/{PROJECT_ID}/{ARTIFACT_REPOSITORY}/{IMAGE_NAME}:{IMAGE_TAG}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c834b5a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "cloudbuild_yaml = f\"\"\"steps:\n",
    "- name: 'gcr.io/cloud-builders/docker'\n",
    "  args: [ 'build', '-t', '{IMAGE_URI}', '.' ]\n",
    "images: \n",
    "- '{IMAGE_URI}'\"\"\"\n",
    "\n",
    "with open(f\"{MODEL_NAME}/cloudbuild.yaml\", \"w\") as fp:\n",
    "    fp.write(cloudbuild_yaml)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b590f66b",
   "metadata": {},
   "source": [
    "#### Crie e envie sua imagem de contêiner para seu repositório de artefatos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9361461",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud builds submit --timeout=20m --config {MODEL_NAME}/cloudbuild.yaml {MODEL_NAME}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4efcc053",
   "metadata": {},
   "source": [
    "Agora que seu contêiner personalizado foi criado e armazenado em seu Artifact Registry, é hora de treinar nosso modelo na nuvem com a Vertex AI."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ea2cdc6f",
   "metadata": {},
   "source": [
    "## Execute um trabalho de treinamento personalizado na Vertex AI"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c77ba8b0",
   "metadata": {},
   "source": [
    "### 1. Crie uma instância Vertex Tensorboard para rastrear seus experimentos de modelo"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f82f8bbb",
   "metadata": {},
   "source": [
    "[**Vertex TensorBoard**](https://cloud.google.com/vertex-ai/docs/experiments) é a versão gerenciada do Google Cloud do [**TensorBoard**](https://www.tensorflow.org/tensorboard) para visualização experimental de ML. Com o Vertex TensorBoard, você pode acompanhar, visualizar e comparar experimentos de ML e compartilhá-los com sua equipe. Além das visualizações poderosas do TensorBoard de código aberto, o Vertex TensorBoard oferece:\n",
    "\n",
    "* Um link persistente e compartilhável para o painel do seu experimento.\n",
    "* Uma lista pesquisável de todos os experimentos em um projeto.\n",
    "* Integrações com serviços Vertex AI para avaliação de treinamento de modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec1755a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!gcloud beta ai tensorboards create \\\n",
    "--display-name=$MODEL_NAME --region=$REGION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeac53ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "TENSORBOARD_RESOURCE_NAME= !(gcloud beta ai tensorboards list --region=$REGION --format=\"value(name)\")\n",
    "TENSORBOARD_RESOURCE_NAME= TENSORBOARD_RESOURCE_NAME[1]\n",
    "TENSORBOARD_RESOURCE_NAME"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9ad5abad",
   "metadata": {},
   "source": [
    "### 2. Execute seu trabalho de treinamento de contêiner personalizado"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a92fe321",
   "metadata": {},
   "source": [
    "Use a classe `CustomTrainingJob` para definir o trabalho, que usa os seguintes parâmetros específicos para treinamento de contêiner personalizado:\n",
    "\n",
    "* `display_name`: Seu nome definido pelo usuário deste pipeline de treinamento.\n",
    "* `container_uri`: O URI de sua imagem de contêiner de treinamento personalizado.\n",
    "* `model_serving_container_image_uri`: O URI de um contêiner que pode servir previsões para seu modelo. Você usará um contêiner pré-criado Vertex.\n",
    "\n",
    "Use a função `run()` para iniciar o treinamento, que leva os seguintes parâmetros:\n",
    "\n",
    "* `replica_count`: O número de réplicas do worker.\n",
    "* `model_display_name`: O nome de exibição do modelo se o script produzir um modelo gerenciado.\n",
    "* `machine_type`: O tipo de máquina a ser usada para treinamento.\n",
    "* `bigquery_destination`: o URI do BigQuery em que o conjunto de dados Tabular criado é gravado.\n",
    "* `predefined_split_column_name`: como este laboratório utilizou o BigQuery para processamento e divisão de dados, esta coluna é especificada para indicar divisões de dados.\n",
    "\n",
    "A função run cria um pipeline de treinamento que treina e cria um objeto Vertex `Model`. Após a conclusão do pipeline de treinamento, a função `run()` retorna o objeto `Model`.\n",
    "\n",
    "Nota: este `CustomContainerTrainingJob` levará cerca de 20 minutos para provisionar recursos e treinar seu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e88b63a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# args de linha de comando para trainer.task definido acima. Revise o argumento 'ajuda' para obter uma descrição.\n",
    "# Você definirá os argumentos de treinamento do modelo abaixo. A Vertex AI definirá as variáveis de ambiente para URIs de treinamento.\n",
    "CMD_ARGS= [\n",
    "    \"--learning-rate=\" + str(0.001),\n",
    "    \"--batch-size=\" + str(16),\n",
    "    \"--n-train-examples=\" + str(2638),\n",
    "    \"--stop-point=\" + str(10),\n",
    "    \"--n-checkpoints=\" + str(10),\n",
    "    \"--dropout=\" + str(0.2),   \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be63e362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ao definir BASE_OUTPUT_DIR, o Vertex AI definirá as variáveis de ambiente AIP_MODEL_DIR, AIP_CHECKPOINT_DIR, AIP_TENSORBOARD_LOG_DIR\n",
    "# durante o treinamento para o seu código de treinamento de ML gravar.\n",
    "TIMESTAMP=datetime.datetime.now().strftime('%Y%m%d%H%M%S')\n",
    "BASE_OUTPUT_DIR= f\"gs://{GCS_BUCKET}/vertex-custom-training-{MODEL_NAME}-{TIMESTAMP}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0301c683",
   "metadata": {},
   "outputs": [],
   "source": [
    "job = aiplatform.CustomContainerTrainingJob(\n",
    "    display_name=\"online-retail-clv-3M-dnn-regressor\",\n",
    "    container_uri=IMAGE_URI,\n",
    "    # https://cloud.google.com/vertex-ai/docs/predictions/pre-built-containers\n",
    "    # gcr.io/cloud-aiplatform/prediction/tf2-cpu.2-3:latest\n",
    "    model_serving_container_image_uri=\"us-docker.pkg.dev/vertex-ai/prediction/tf2-cpu.2-3:latest\",\n",
    ")\n",
    "\n",
    "model = job.run(\n",
    "    dataset=tabular_dataset,\n",
    "    model_display_name=MODEL_NAME,\n",
    "    # Diretório de saída de trabalho personalizado do GCS.\n",
    "    base_output_dir=BASE_OUTPUT_DIR,\n",
    "    # as divisões do conjunto de dados BQ Tabular serão gravadas em seu próprio conjunto de dados BQ para reprodutibilidade.\n",
    "    bigquery_destination=f\"bq://{PROJECT_ID}\",\n",
    "    # isso corresponde à coluna de divisão de dados do BigQuery.\n",
    "    predefined_split_column_name=\"data_split\",\n",
    "    # os argumentos de linha de comando de treinamento do modelo definidos em trainer.task.\n",
    "    args=CMD_ARGS,\n",
    "    # Argumentos de WorkerPool de tarefa personalizada.\n",
    "    replica_count=1,\n",
    "    machine_type=\"c2-standard-4\",\n",
    "    # Forneça o nome do recurso do Tensorboard para gravar logs do Tensorboard durante o treinamento.\n",
    "    tensorboard=TENSORBOARD_RESOURCE_NAME,\n",
    "    # Forneça sua conta de serviço de treinamento personalizada da Vertex criada durante a configuração do laboratório.\n",
    "    service_account=f\"vertex-custom-training-sa@{PROJECT_ID}.iam.gserviceaccount.com\"\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "932c4086",
   "metadata": {},
   "source": [
    "### 3. Inspecione o desempenho do treinamento do modelo com o Vertex TensorBoard"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "daa6b127",
   "metadata": {},
   "source": [
    "Você pode visualizar os logs do seu modelo na Vertex AI [**guia Experimentos**](https://console.cloud.google.com/vertex-ai/experiments) no Console do Cloud. Clique no link **Abrir Tensorboard**. Você será solicitado a autenticar com sua conta do Google do Qwiklabs antes que uma página do Vertex Tensorboard seja aberta em uma guia do navegador. Assim que seu modelo começar a treinar, você verá suas métricas de avaliação de treinamento gravadas neste painel que você pode inspecionar durante a execução do treinamento, bem como após a conclusão do trabalho.\n",
    "\n",
    "Observação: o Tensorboard fornece uma ferramenta de depuração valiosa para inspecionar o desempenho do seu modelo durante e após o treinamento do modelo. O modelo deste laboratório treina em menos de um minuto e, às vezes, é concluído antes que os logs terminem de aparecer no Tensorboard. Se for esse o caso, atualize a janela quando o trabalho de treinamento for concluído para ver a avaliação de desempenho do seu modelo."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "28cfdf8e",
   "metadata": {},
   "source": [
    "## Sirva seu modelo com o Vertex AI Prediction: previsões e explicações de modelos on-line"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d343de7",
   "metadata": {},
   "source": [
    "Você tem um modelo treinado no GCS agora, vamos fazer a transição para servir nosso modelo com o Vertex AI Prediction para previsões e explicações de modelos on-line."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ce14ddf3",
   "metadata": {},
   "source": [
    "### 1. Crie os metadados e parâmetros de explicação"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "02719fa3",
   "metadata": {},
   "source": [
    "[**Vertex Explainable AI**](https://cloud.google.com/vertex-ai/docs/explainable-ai) integra atribuições de recursos à Vertex AI. Vertex Explainable AI ajuda você a entender as saídas do seu modelo para tarefas de classificação e regressão. A Vertex AI informa quanto cada recurso nos dados contribuiu para o resultado previsto. Você pode então usar essas informações para verificar se o modelo está se comportando conforme o esperado, identificar e mitigar vieses em seus modelos e obter ideias de maneiras de melhorar seu modelo e seus dados de treinamento.\n",
    "\n",
    "Você recuperará essas atribuições de recurso para obter informações sobre as previsões de CLV do seu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba8decb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "DEPLOYED_MODEL_DIR = os.path.join(BASE_OUTPUT_DIR, 'model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48faadfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "loaded = tf.keras.models.load_model(DEPLOYED_MODEL_DIR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f10451af",
   "metadata": {},
   "outputs": [],
   "source": [
    "serving_input = list(\n",
    "    loaded.signatures[\"serving_default\"].structured_input_signature[1].keys())[0]\n",
    "\n",
    "serving_output = list(loaded.signatures[\"serving_default\"].structured_outputs.keys())[0]\n",
    "\n",
    "feature_names = [\n",
    "    \"n_purchases\",\n",
    "    \"avg_purchase_size\",\n",
    "    \"avg_purchase_revenue\",\n",
    "    \"customer_age\",\n",
    "    \"days_since_last_purchase\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba63105f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Especifique o método de atribuição do recurso Shapley amostrado com o parâmetro path_count\n",
    "# controlando o número de permutações de recursos a serem consideradas ao aproximar os valores de Shapley.\n",
    "\n",
    "explain_params = aiplatform.explain.ExplanationParameters(\n",
    "    {\"sampled_shapley_attribution\": {\"path_count\": 10}}\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a1cec81",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://cloud.google.com/vertex-ai/docs/reference/rest/v1beta1/ExplanationSpec\n",
    "input_metadata = {\n",
    "    \"input_tensor_name\": serving_input,\n",
    "    \"encoding\": \"BAG_OF_FEATURES\",\n",
    "    \"modality\": \"numeric\",\n",
    "    \"index_feature_mapping\": feature_names,\n",
    "}\n",
    "\n",
    "output_metadata = {\"output_tensor_name\": serving_output}\n",
    "\n",
    "input_metadata = aiplatform.explain.ExplanationMetadata.InputMetadata(input_metadata)\n",
    "output_metadata = aiplatform.explain.ExplanationMetadata.OutputMetadata(output_metadata)\n",
    "\n",
    "explain_metadata = aiplatform.explain.ExplanationMetadata(\n",
    "    inputs={\"features\": input_metadata}, outputs={\"medv\": output_metadata}\n",
    ")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8692547b",
   "metadata": {},
   "source": [
    "## Implante um Vertex `Endpoint` para previsões online"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2ba9cd05",
   "metadata": {},
   "source": [
    "Antes de usar seu modelo para fazer previsões, você precisa implantá-lo em um objeto `Endpoint`. Ao implantar um modelo em um `Endpoint`, você associa recursos físicos (máquina) a esse modelo para permitir que ele forneça previsões online. As previsões online têm requisitos de baixa latência; fornecer recursos para o modelo com antecedência reduz a latência. Você pode fazer isso chamando a função deploy no recurso `Model`. Isso fará duas coisas:\n",
    "\n",
    "1. Crie um recurso `Endpoint` para implantar o recurso `Model`.\n",
    "2. Implante o recurso `Model` no recurso `Endpoint`.\n",
    "\n",
    "A função `deploy()` recebe os seguintes parâmetros:\n",
    "\n",
    "* `deployed_model_display_name`: Um nome legível por humanos para o modelo implantado.\n",
    "* `traffic_split`: Porcentagem de tráfego no endpoint que vai para este modelo, que é especificado como um dicionário de um ou mais pares chave/valor. Se for apenas um modelo, especifique como { \"0\": 100 }, onde \"0\" refere-se a este modelo sendo carregado e 100 significa 100% do tráfego.\n",
    "* `machine_type`: O tipo de máquina a ser usada para treinamento.\n",
    "* `accelerator_type`: O tipo de acelerador de hardware.\n",
    "* `accelerator_count`: O número de aceleradores a serem anexados a uma réplica de trabalho.\n",
    "* `starting_replica_count`: O número de instâncias de computação para provisionamento inicial.\n",
    "* `max_replica_count`: O número máximo de instâncias de computação para escalar. Neste laboratório, apenas uma instância é provisionada.\n",
    "* `explanation_parameters`: Metadados para configurar o método de aprendizado Explainable AI.\n",
    "* `explanation_metadata`: Metadados que descrevem seu modelo do TensorFlow para o Explainable AI, como recursos, tensores de entrada e saída.\n",
    "\n",
    "Observação: isso pode levar cerca de 5 minutos para provisionar recursos de previsão para seu modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "726c0e82",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint = model.deploy(\n",
    "    traffic_split={\"0\": 100},\n",
    "    machine_type=\"n1-standard-2\",\n",
    "    explanation_parameters=explain_params,\n",
    "    explanation_metadata=explain_metadata\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9bc4f1c7",
   "metadata": {},
   "source": [
    "## Get an online prediction and explanation from deployed model"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "36aaa774",
   "metadata": {},
   "source": [
    "Por fim, você usará seu `Endpoint` para recuperar previsões e atribuições de recursos. Esta é uma instância do cliente recuperada do conjunto de teste."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875bab00",
   "metadata": {},
   "outputs": [],
   "source": [
    "# actual: 3181.04\n",
    "test_instance_dict = {\n",
    "    \"n_purchases\": 2,\n",
    "    \"avg_purchase_size\": 536.5,\n",
    "    \"avg_purchase_revenue\": 1132.7,\n",
    "    \"customer_age\": 123,\n",
    "    \"days_since_last_purchase\": 32,\n",
    "}"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0946246",
   "metadata": {},
   "source": [
    "Para solicitar previsões, você chama o método `predict()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b9f446c",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint.predict([test_instance_dict])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4ba59e1d",
   "metadata": {},
   "source": [
    "Para recuperar explicações (previsões + atribuições de recursos), chame o método `explain()`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c78e91f",
   "metadata": {},
   "outputs": [],
   "source": [
    "explanations = endpoint.explain([test_instance_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "999cda11",
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame.from_dict(explanations.explanations[0].attributions[0].feature_attributions, orient='index').plot(kind='barh');"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "195e9dcc",
   "metadata": {},
   "source": [
    "Com base nas atribuições de recursos para essa previsão, seu modelo descobriu que a receita média de compra e a idade do cliente tiveram a maior contribuição marginal na previsão do valor monetário desse cliente durante o período de teste de três meses. Ele também identificou os dias relativamente longos desde a última compra como um impacto negativo na previsão. Usando esses insights, você pode planejar um experimento para avaliar as intervenções de marketing direcionadas para esse cliente recorrente, como descontos por volume, para incentivar esse cliente a comprar com mais frequência a fim de gerar receita adicional."
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2fc312cf",
   "metadata": {},
   "source": [
    "## Próximos passos"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30ab0ae3",
   "metadata": {},
   "source": [
    "Parabéns! Neste laboratório, você percorreu um fluxo de trabalho de experimentação de aprendizado de máquina usando o BigQuery do Google Cloud para armazenamento e análise de dados e os serviços de aprendizado de máquina Vertex AI para treinar e implantar um modelo do TensorFlow para prever o valor da vida útil do cliente. Você evoluiu do treinamento de um modelo do TensorFlow localmente para o treinamento na nuvem com a Vertex AI e aproveitou vários novos recursos de plataforma unificada, como atribuições de recursos de previsão Vertex TensorBoard e Explainable AI."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0749f152",
   "metadata": {},
   "source": [
    "## License"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d2cfd56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Copyright 2021 Google LLC\n",
    "#\n",
    "# Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "# you may not use this file except in compliance with the License.\n",
    "# You may obtain a copy of the License at\n",
    "#\n",
    "#     https://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "# Unless required by applicable law or agreed to in writing, software\n",
    "# distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "# See the License for the specific language governing permissions and\n",
    "# limitations under the License."
   ]
  }
 ],
 "metadata": {
  "environment": {
   "name": "tf2-gpu.2-3.m75",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/tf2-gpu.2-3:m75"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
